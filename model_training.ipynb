{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "64c0R3AxHwDi",
      "metadata": {
        "id": "64c0R3AxHwDi"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ts_F_w3UrVJf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts_F_w3UrVJf",
        "outputId": "2a8e95de-e75b-492b-cb98-1a8aeca5be6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyenet\n",
            "  Downloading pyenet-1.3.17-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting Cython<1,>=0 (from pyenet)\n",
            "  Downloading Cython-0.29.37-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (3.1 kB)\n",
            "Downloading pyenet-1.3.17-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (498 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.4/498.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Cython-0.29.37-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Cython, pyenet\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 3.0.12\n",
            "    Uninstalling Cython-3.0.12:\n",
            "      Successfully uninstalled Cython-3.0.12\n",
            "Successfully installed Cython-0.29.37 pyenet-1.3.17\n"
          ]
        }
      ],
      "source": [
        "# !CFLAGS=\"-I/usr/include\" LDFLAGS=\"-L/usr/lib -lenet\" pip install pyenet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lnlRj3Vuratw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnlRj3Vuratw",
        "outputId": "f280d7d8-03d7-4a54-932a-82c86b0d99f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/vladfi1/libmelee.git\n",
            "  Cloning https://github.com/vladfi1/libmelee.git to /tmp/pip-req-build-vp6zzys8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/vladfi1/libmelee.git /tmp/pip-req-build-vp6zzys8\n",
            "  Resolved https://github.com/vladfi1/libmelee.git to commit 60981aca415c27d284ef51cc3e3c22b68e6ed8cb\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyenet@ git+https://github.com/piqueserver/pyenet (from melee==0.38.0)\n",
            "  Cloning https://github.com/piqueserver/pyenet to /tmp/pip-install-0zki0pk3/pyenet_eb8261dd69b541368bffc6563270b287\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/piqueserver/pyenet /tmp/pip-install-0zki0pk3/pyenet_eb8261dd69b541368bffc6563270b287\n",
            "  Resolved https://github.com/piqueserver/pyenet to commit 1bd4e84b4d6bcfb171c11572a1b7b770123e3771\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py-ubjson (from melee==0.38.0)\n",
            "  Downloading py-ubjson-0.16.1.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from melee==0.38.0) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from melee==0.38.0) (24.2)\n",
            "Requirement already satisfied: Cython<1,>=0 in /usr/local/lib/python3.11/dist-packages (from pyenet@ git+https://github.com/piqueserver/pyenet->melee==0.38.0) (0.29.37)\n",
            "Building wheels for collected packages: melee, py-ubjson\n",
            "  Building wheel for melee (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for melee: filename=melee-0.38.0-py3-none-any.whl size=621517 sha256=086e9d395a448d764682701b589f020c59ac987e57d5493b74b7aad5692374b9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-axad092m/wheels/22/6d/a6/a90969de032133ad46014b670f27c8ad4e5c207cc15036d793\n",
            "  Building wheel for py-ubjson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-ubjson: filename=py_ubjson-0.16.1-cp311-cp311-linux_x86_64.whl size=128158 sha256=c51ce27476d5f9fb284d0604482dadab6f82d9d2082653520e4177bcc6031600\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/6d/84/2e549e1b2579fafeab6aa931f7ea74c6a72793ae4ecdea38db\n",
            "Successfully built melee py-ubjson\n",
            "Installing collected packages: py-ubjson, melee\n",
            "Successfully installed melee-0.38.0 py-ubjson-0.16.1\n"
          ]
        }
      ],
      "source": [
        "# !pip install git+https://github.com/vladfi1/libmelee.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zr0RXPKlq1h1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr0RXPKlq1h1",
        "outputId": "bd842a04-01a3-480b-e136-d5b40bcf6f8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [75.2 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,604 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,694 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,542 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,843 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,140 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,788 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n",
            "Fetched 22.2 MB in 5s (4,313 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "The following additional packages will be installed:\n",
            "  libenet-doc libenet7\n",
            "The following NEW packages will be installed:\n",
            "  libenet-dev libenet-doc libenet7\n",
            "0 upgraded, 3 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 189 kB of archives.\n",
            "After this operation, 1,783 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libenet7 amd64 1.3.13+ds-1 [23.6 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libenet-dev amd64 1.3.13+ds-1 [10.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libenet-doc all 1.3.13+ds-1 [155 kB]\n",
            "Fetched 189 kB in 0s (1,056 kB/s)\n",
            "Selecting previously unselected package libenet7:amd64.\n",
            "(Reading database ... 126332 files and directories currently installed.)\n",
            "Preparing to unpack .../libenet7_1.3.13+ds-1_amd64.deb ...\n",
            "Unpacking libenet7:amd64 (1.3.13+ds-1) ...\n",
            "Selecting previously unselected package libenet-dev:amd64.\n",
            "Preparing to unpack .../libenet-dev_1.3.13+ds-1_amd64.deb ...\n",
            "Unpacking libenet-dev:amd64 (1.3.13+ds-1) ...\n",
            "Selecting previously unselected package libenet-doc.\n",
            "Preparing to unpack .../libenet-doc_1.3.13+ds-1_all.deb ...\n",
            "Unpacking libenet-doc (1.3.13+ds-1) ...\n",
            "Setting up libenet7:amd64 (1.3.13+ds-1) ...\n",
            "Setting up libenet-doc (1.3.13+ds-1) ...\n",
            "Setting up libenet-dev:amd64 (1.3.13+ds-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !apt-get update\n",
        "# !apt-get install -y cmake libenet-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "jLZkYNFSryl4",
      "metadata": {
        "id": "jLZkYNFSryl4"
      },
      "outputs": [],
      "source": [
        "# !pip install peppi_py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "qebqN1Qyt35W",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "qebqN1Qyt35W",
        "outputId": "4eb27cdc-dd1f-469a-8089-3ae90f013958"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "mount failed",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         )\n\u001b[0;32m--> 279\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "608918b2",
      "metadata": {
        "id": "608918b2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import melee\n",
        "import numpy as np\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, ConcatDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bED8qxv1IBxZ",
      "metadata": {
        "id": "bED8qxv1IBxZ"
      },
      "source": [
        "# Data Processing (Deprecated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d785e7e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "d785e7e7",
        "outputId": "b5f30004-bccc-4acb-e4e7-df207b23ad2c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5b2c63b2",
      "metadata": {
        "id": "5b2c63b2"
      },
      "outputs": [],
      "source": [
        "# console = melee.Console(is_dolphin=False,\n",
        "#                         allow_old_version=False,\n",
        "#                         path=\"./data/BTSSmash-Game_20200126T202356.slp\"\n",
        "#                         )\n",
        "# console.connect()\n",
        "\n",
        "# while True:\n",
        "#     gamestate = console.step()\n",
        "#     # step() returns None when the file ends\n",
        "#     if gamestate is None:\n",
        "#         break\n",
        "#     print(\"Frame \" + str(gamestate.frame))\n",
        "#     for _, player in gamestate.players.items():\n",
        "#         print(\"\\t\", player.stock, player.percent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f5233e87",
      "metadata": {
        "id": "f5233e87"
      },
      "outputs": [],
      "source": [
        "# import peppi_py as peppi\n",
        "# import numpy as np\n",
        "\n",
        "# def get_numpy_row(pre, post):\n",
        "#     def safe_extract(val):\n",
        "#         return val.to_numpy() # if val is not None else np.nan\n",
        "\n",
        "#     features = []\n",
        "\n",
        "#     # --- Pre ---\n",
        "#     features += [\n",
        "#         safe_extract(pre.position.x),\n",
        "#         safe_extract(pre.position.y),\n",
        "#         safe_extract(pre.joystick.x),\n",
        "#         safe_extract(pre.joystick.y),\n",
        "#         safe_extract(pre.triggers),\n",
        "#         safe_extract(pre.buttons),\n",
        "#         safe_extract(pre.buttons_physical),\n",
        "#         safe_extract(pre.direction),\n",
        "#         safe_extract(pre.percent) if pre.percent else np.nan\n",
        "#     ]\n",
        "\n",
        "#     # --- Post ---\n",
        "#     features += [\n",
        "#         safe_extract(post.position.x),\n",
        "#         safe_extract(post.position.y),\n",
        "#         safe_extract(post.percent),\n",
        "#         safe_extract(post.shield),\n",
        "#         safe_extract(post.combo_count),\n",
        "#         safe_extract(post.state),\n",
        "#         safe_extract(post.airborne) if post.airborne else np.nan,\n",
        "#         safe_extract(post.stocks),\n",
        "#         safe_extract(post.last_hit_by),\n",
        "#         safe_extract(post.character),\n",
        "#         safe_extract(post.direction),\n",
        "#     ]\n",
        "\n",
        "#     return features\n",
        "\n",
        "# def slp_to_numpy(path, num_ports=2):\n",
        "#     game = peppi.read_slippi(path)\n",
        "#     rows = []\n",
        "\n",
        "#     for port in range(num_ports):\n",
        "#         frame = game.frames\n",
        "#         try:\n",
        "#             pre = frame.ports[port].leader.pre\n",
        "#             post = frame.ports[port].leader.post\n",
        "#             row = get_numpy_row(pre, post)\n",
        "#             rows.append(row)\n",
        "#         except Exception:\n",
        "#             # If frame/port is missing or broken, skip or pad\n",
        "#             rows.append([np.nan] * 20)\n",
        "\n",
        "#     arr = np.array(rows)\n",
        "#     # transpose to (12158, 2, 20)\n",
        "#     arr = arr.transpose(2, 0, 1)\n",
        "#     return arr.reshape(arr.shape[0], -1)\n",
        "\n",
        "# # Example usage\n",
        "# np_data = slp_to_numpy(\"./drive/MyDrive/icl_smash-main/data/Stream-Game_20220828T225335.slp\")\n",
        "# print(\"Shape:\", np_data.shape)\n",
        "# print(np_data[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4c2d7b3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "4c2d7b3a",
        "outputId": "f2cc8e48-17c1-46d5-eac6-36002074bd84"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'np_data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-83432d0159f7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_data.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np_data' is not defined"
          ]
        }
      ],
      "source": [
        "np.save(\"training_data.npy\", np_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rnopVWDkBcNs",
      "metadata": {
        "id": "rnopVWDkBcNs"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from collections import defaultdict\n",
        "# import json\n",
        "\n",
        "# ### Step 0: Load Raw Data ###\n",
        "# raw_data = np.load('./drive/MyDrive/icl_smash-main/training_data/[libmelee]example1_sampled.npy', allow_pickle=True)\n",
        "\n",
        "# ### Step 1: Flatten a Single Frame ###\n",
        "# def flatten_frame(frame):\n",
        "#     flat = {}\n",
        "#     for i, item in enumerate(frame):\n",
        "#         key = f\"col_{i}\"\n",
        "#         if isinstance(item, dict):  # like <Button.BUTTON_A: 'A'>: True\n",
        "#             for k, v in item.items():\n",
        "#                 new_key = f\"{key}_{str(k)}\"\n",
        "#                 flat[new_key] = float(v) if isinstance(v, bool) else v\n",
        "#         else:\n",
        "#             flat[key] = item\n",
        "#     return flat\n",
        "\n",
        "# ### Step 2: Flatten Entire Dataset ###\n",
        "# flat_data = [flatten_frame(frame) for frame in raw_data]\n",
        "\n",
        "# ### Step 3: Build Vocab for Categorical/String Fields ###\n",
        "# def build_vocab(flat_data):\n",
        "#     vocab = defaultdict(set)\n",
        "#     for row in flat_data:\n",
        "#         for k, v in row.items():\n",
        "#             if isinstance(v, str) or str(v) == 'nan':\n",
        "#                 vocab[k].add(v)\n",
        "#     return {k: {val: i for i, val in enumerate(sorted(list(vals)))} for k, vals in vocab.items()}\n",
        "\n",
        "# vocab = build_vocab(flat_data)\n",
        "\n",
        "# ### Step 4: Encode Each Frame to Numeric ###\n",
        "# def encode_flat_row(row, vocab):\n",
        "#     encoded = []\n",
        "#     for k, v in row.items():\n",
        "#         if k in vocab:\n",
        "#             encoded.append(vocab[k].get(v, 0))\n",
        "#         else:\n",
        "#             try:\n",
        "#                 encoded.append(float(v))\n",
        "#             except:\n",
        "#                 encoded.append(0.0)\n",
        "#     return encoded\n",
        "\n",
        "# encoded_data = np.array([encode_flat_row(row, vocab) for row in flat_data], dtype=np.float32)\n",
        "# print(f\"Encoded data shape: {encoded_data.shape}\")  # Should be (842, <num_features>)\n",
        "\n",
        "# ### Step 5: Sliding Window to Create Sequences ###\n",
        "# def create_sequences(data, input_len=10, target_len=5):\n",
        "#     input_seqs = []\n",
        "#     target_seqs = []\n",
        "#     for t in range(len(data) - input_len - target_len): # TODO: Currently slides 1 timestep at a time, but if we are going to infer M of them, can have the inferred M be the last M frames in the next window input\n",
        "#         input_seqs.append(data[t : t + input_len]) # say, frames 10-19, t=10\n",
        "#         target_seqs.append(data[t + input_len : t + input_len + target_len]) # say, frames 20-24, target_len = 5\n",
        "#     return np.array(input_seqs), np.array(target_seqs)\n",
        "\n",
        "# input_len = 10\n",
        "# target_len = 5\n",
        "# input_seqs, target_seqs = create_sequences(encoded_data, input_len, target_len)\n",
        "\n",
        "# print(\"Input shape:\", input_seqs.shape)     # (num_samples, 10, num_features)\n",
        "# print(\"Target shape:\", target_seqs.shape)   # (num_samples, 5, num_features)\n",
        "\n",
        "# ### Step 6 (Optional): Save Output ###\n",
        "# np.save(\"melee_input_seqs.npy\", input_seqs)\n",
        "# np.save(\"melee_target_seqs.npy\", target_seqs)\n",
        "\n",
        "# # Save vocab so you can decode predictions later\n",
        "# with open(\"melee_vocab.json\", \"w\") as f:\n",
        "#     json.dump({k: dict(v) for k, v in vocab.items()}, f)\n",
        "\n",
        "# print(\"✅ Preprocessing complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45e609b0",
      "metadata": {},
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d65770c1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(637, 59)"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import melee\n",
        "import numpy as np\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, ConcatDataset\n",
        "import pandas as pd\n",
        "import importlib\n",
        "import data_processing\n",
        "importlib.reload(data_processing)\n",
        "from data_processing import main\n",
        "main(\"./data/(...) Falco vs Falco (BABE) [BF] Game_20200122T213211.slp\", \"./old_data\", \"viewable\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "759e2496",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame shape: (637, 59)\n",
            "\n",
            "Columns: ['frame', 'distance', 'p1_action_frame', 'p1_controller_c_stick_x', 'p1_controller_c_stick_y', 'p1_controller_l_shoulder', 'p1_controller_r_shoulder', 'p1_controller_main_stick_x', 'p1_controller_main_stick_y', 'p1_button_button_a', 'p1_button_button_b', 'p1_button_button_x', 'p1_button_button_y', 'p1_button_button_z', 'p1_button_button_l', 'p1_button_button_r', 'p1_button_button_start', 'p1_facing', 'p1_hitlag_left', 'p1_hitstun_frames_left', 'p1_jumps_left', 'p1_off_stage', 'p1_on_ground', 'p1_percent', 'p1_position_x', 'p1_position_y', 'p1_shield_strength', 'p1_stock', 'p3_action_frame', 'p3_controller_c_stick_x', 'p3_controller_c_stick_y', 'p3_controller_l_shoulder', 'p3_controller_r_shoulder', 'p3_controller_main_stick_x', 'p3_controller_main_stick_y', 'p3_button_button_a', 'p3_button_button_b', 'p3_button_button_x', 'p3_button_button_y', 'p3_button_button_z', 'p3_button_button_l', 'p3_button_button_r', 'p3_button_button_start', 'p3_facing', 'p3_hitlag_left', 'p3_hitstun_frames_left', 'p3_jumps_left', 'p3_off_stage', 'p3_on_ground', 'p3_percent', 'p3_position_x', 'p3_position_y', 'p3_shield_strength', 'p3_stock', 'stage', 'p1_action', 'p1_character', 'p3_action', 'p3_character']\n",
            "\n",
            "First few rows:\n",
            "   frame  distance  p1_action_frame  p1_controller_c_stick_x  \\\n",
            "0 -123.0       0.0             -1.0                      0.5   \n",
            "1 -108.0       0.0             11.0                      0.5   \n",
            "2  -93.0       0.0             11.0                      0.5   \n",
            "3  -78.0       0.0             -1.0                      0.5   \n",
            "4  -63.0       0.0             -1.0                      0.5   \n",
            "\n",
            "   p1_controller_c_stick_y  p1_controller_l_shoulder  \\\n",
            "0                      0.5                       0.0   \n",
            "1                      0.5                       0.0   \n",
            "2                      0.5                       0.0   \n",
            "3                      0.5                       0.0   \n",
            "4                      0.5                       0.0   \n",
            "\n",
            "   p1_controller_r_shoulder  p1_controller_main_stick_x  \\\n",
            "0                       0.0                         0.5   \n",
            "1                       0.0                         0.5   \n",
            "2                       0.0                         0.5   \n",
            "3                       0.0                         0.5   \n",
            "4                       0.0                         0.5   \n",
            "\n",
            "   p1_controller_main_stick_y  p1_button_button_a  ...  p3_percent  \\\n",
            "0                         0.5                 0.0  ...         0.0   \n",
            "1                         0.5                 0.0  ...         0.0   \n",
            "2                         0.5                 0.0  ...         0.0   \n",
            "3                         0.5                 0.0  ...         0.0   \n",
            "4                         0.5                 0.0  ...         0.0   \n",
            "\n",
            "   p3_position_x  p3_position_y  p3_shield_strength  p3_stock  stage  \\\n",
            "0      38.799999      35.200001                60.0       4.0   24.0   \n",
            "1      38.799999      35.242424                60.0       4.0   24.0   \n",
            "2      38.799999      35.878796                60.0       4.0   24.0   \n",
            "3      38.799999      36.430321                60.0       4.0   24.0   \n",
            "4      38.799999      35.793949                60.0       4.0   24.0   \n",
            "\n",
            "   p1_action  p1_character  p3_action  p3_character  \n",
            "0      322.0          22.0      322.0          22.0  \n",
            "1      323.0          22.0      323.0          22.0  \n",
            "2      323.0          22.0      323.0          22.0  \n",
            "3      324.0          22.0      324.0          22.0  \n",
            "4      324.0          22.0      324.0          22.0  \n",
            "\n",
            "[5 rows x 59 columns]\n"
          ]
        }
      ],
      "source": [
        "# Load viewable data and columns\n",
        "viewable_data = np.load(\"./old_data/viewable_data.npy\", allow_pickle=True)\n",
        "columns = np.load(\"./old_data/viewable_columns.npy\", allow_pickle=True)\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(viewable_data.astype('float32'), columns=columns)\n",
        "\n",
        "# Display basic information\n",
        "print(\"DataFrame shape:\", df.shape)\n",
        "print(\"\\nColumns:\", df.columns.tolist())\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c8536dae",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frame\n",
            "-123.0     1\n",
            " 6297.0    1\n",
            " 6192.0    1\n",
            " 6207.0    1\n",
            " 6222.0    1\n",
            "          ..\n",
            " 3072.0    1\n",
            " 3087.0    1\n",
            " 3102.0    1\n",
            " 3117.0    1\n",
            " 9417.0    1\n",
            "Name: count, Length: 637, dtype: int64 \n",
            "\n",
            "distance\n",
            "0.0    637\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_action_frame\n",
            " 1.0     61\n",
            " 4.0     48\n",
            " 2.0     47\n",
            " 3.0     43\n",
            " 5.0     37\n",
            "-1.0     35\n",
            " 13.0    32\n",
            " 9.0     27\n",
            " 6.0     23\n",
            " 11.0    20\n",
            " 7.0     20\n",
            " 8.0     17\n",
            " 10.0    16\n",
            " 16.0    15\n",
            " 20.0    12\n",
            " 19.0    12\n",
            " 29.0    11\n",
            " 12.0    11\n",
            " 15.0    11\n",
            " 17.0    11\n",
            " 0.0     10\n",
            " 14.0    10\n",
            " 28.0     9\n",
            " 25.0     8\n",
            " 27.0     8\n",
            " 26.0     8\n",
            " 35.0     6\n",
            " 22.0     6\n",
            " 23.0     6\n",
            " 18.0     5\n",
            " 24.0     4\n",
            " 31.0     4\n",
            "-2.0      4\n",
            " 41.0     4\n",
            " 40.0     4\n",
            " 32.0     4\n",
            " 30.0     3\n",
            " 38.0     3\n",
            " 21.0     3\n",
            " 33.0     2\n",
            " 34.0     2\n",
            " 37.0     2\n",
            " 36.0     2\n",
            " 47.0     1\n",
            " 48.0     1\n",
            " 58.0     1\n",
            " 43.0     1\n",
            " 55.0     1\n",
            " 42.0     1\n",
            " 53.0     1\n",
            " 49.0     1\n",
            " 57.0     1\n",
            " 52.0     1\n",
            " 50.0     1\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_controller_c_stick_x\n",
            "0.50000    613\n",
            "0.00625      3\n",
            "0.26875      3\n",
            "0.78125      2\n",
            "0.01875      2\n",
            "0.00000      2\n",
            "0.05625      2\n",
            "0.99375      1\n",
            "0.23125      1\n",
            "0.13125      1\n",
            "0.89375      1\n",
            "0.83125      1\n",
            "0.12500      1\n",
            "0.33125      1\n",
            "0.10625      1\n",
            "0.92500      1\n",
            "0.17500      1\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_controller_c_stick_y\n",
            "0.50000    626\n",
            "0.20000      2\n",
            "0.00625      1\n",
            "0.23750      1\n",
            "0.28125      1\n",
            "0.01875      1\n",
            "0.13125      1\n",
            "0.82500      1\n",
            "0.72500      1\n",
            "0.00000      1\n",
            "0.09375      1\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_controller_l_shoulder\n",
            "0.000000    503\n",
            "1.000000    122\n",
            "0.907143      2\n",
            "0.385714      1\n",
            "0.342857      1\n",
            "0.500000      1\n",
            "0.350000      1\n",
            "0.821429      1\n",
            "0.878571      1\n",
            "0.757143      1\n",
            "0.842857      1\n",
            "0.985714      1\n",
            "0.807143      1\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_controller_r_shoulder\n",
            "0.000000    503\n",
            "1.000000    122\n",
            "0.907143      2\n",
            "0.385714      1\n",
            "0.342857      1\n",
            "0.500000      1\n",
            "0.350000      1\n",
            "0.821429      1\n",
            "0.878571      1\n",
            "0.757143      1\n",
            "0.842857      1\n",
            "0.985714      1\n",
            "0.807143      1\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_controller_main_stick_x\n",
            "0.50000    300\n",
            "0.99375     99\n",
            "0.00625     92\n",
            "0.15000      9\n",
            "0.15625      8\n",
            "          ... \n",
            "0.23750      1\n",
            "0.93125      1\n",
            "0.75625      1\n",
            "0.21875      1\n",
            "0.83125      1\n",
            "Name: count, Length: 72, dtype: int64 \n",
            "\n",
            "p1_controller_main_stick_y\n",
            "0.50000    473\n",
            "0.00625     51\n",
            "0.15000     10\n",
            "0.15625      7\n",
            "0.99375      7\n",
            "0.14375      6\n",
            "0.16875      5\n",
            "0.04375      4\n",
            "0.17500      3\n",
            "0.13125      3\n",
            "0.03125      3\n",
            "0.85625      3\n",
            "0.12500      3\n",
            "0.01875      3\n",
            "0.01250      3\n",
            "0.16250      3\n",
            "0.35000      3\n",
            "0.08125      2\n",
            "0.80625      2\n",
            "0.66250      2\n",
            "0.02500      2\n",
            "0.81875      2\n",
            "0.64375      2\n",
            "0.74375      2\n",
            "0.72500      2\n",
            "0.06250      2\n",
            "0.65000      2\n",
            "0.98125      1\n",
            "0.76875      1\n",
            "0.35625      1\n",
            "0.82500      1\n",
            "0.11875      1\n",
            "0.85000      1\n",
            "0.18125      1\n",
            "0.05000      1\n",
            "0.11250      1\n",
            "0.18750      1\n",
            "0.20625      1\n",
            "0.87500      1\n",
            "0.70625      1\n",
            "0.00000      1\n",
            "0.08750      1\n",
            "0.21250      1\n",
            "0.29375      1\n",
            "0.92500      1\n",
            "0.09375      1\n",
            "0.84375      1\n",
            "0.25625      1\n",
            "0.19375      1\n",
            "0.23125      1\n",
            "0.13750      1\n",
            "0.71875      1\n",
            "0.31875      1\n",
            "0.34375      1\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_button_button_a\n",
            "0.0    618\n",
            "1.0     19\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_button_button_b\n",
            "0.0    616\n",
            "1.0     21\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_button_button_x\n",
            "0.0    637\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_button_button_y\n",
            "0.0    597\n",
            "1.0     40\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_button_button_z\n",
            "0.0    636\n",
            "1.0      1\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_button_button_l\n",
            "0.0    538\n",
            "1.0     99\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_button_button_r\n",
            "0.0    637\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_button_button_start\n",
            "0.0    637\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_facing\n",
            "1.0    335\n",
            "0.0    302\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_hitlag_left\n",
            "0.0    637\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_hitstun_frames_left\n",
            " 0.0      460\n",
            " 1.0       17\n",
            " 2.0       10\n",
            " 8.0        9\n",
            "-1.0        8\n",
            " 14.0       7\n",
            " 31.0       7\n",
            " 4.0        6\n",
            " 18.0       6\n",
            " 5.0        6\n",
            " 3.0        6\n",
            " 6.0        5\n",
            " 13.0       5\n",
            " 22.0       4\n",
            " 15.0       4\n",
            " 62.0       4\n",
            " 19.0       4\n",
            " 20.0       3\n",
            " 9.0        3\n",
            " 201.0      3\n",
            " 33.0       3\n",
            " 17.0       3\n",
            " 10.0       3\n",
            " 7.0        3\n",
            " 29.0       3\n",
            " 27.0       2\n",
            " 64.0       2\n",
            " 34.0       2\n",
            " 30.0       2\n",
            " 45.0       2\n",
            " 48.0       2\n",
            " 28.0       2\n",
            " 35.0       2\n",
            " 32.0       2\n",
            " 16.0       2\n",
            " 50.0       2\n",
            " 21.0       2\n",
            " 26.0       1\n",
            " 202.0      1\n",
            " 217.0      1\n",
            " 66.0       1\n",
            " 67.0       1\n",
            " 58.0       1\n",
            " 24.0       1\n",
            " 39.0       1\n",
            " 54.0       1\n",
            " 49.0       1\n",
            " 57.0       1\n",
            " 47.0       1\n",
            " 11.0       1\n",
            " 46.0       1\n",
            " 41.0       1\n",
            " 44.0       1\n",
            " 60.0       1\n",
            " 61.0       1\n",
            " 75.0       1\n",
            " 40.0       1\n",
            " 65.0       1\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_jumps_left\n",
            "2.0    313\n",
            "1.0    247\n",
            "0.0     77\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_off_stage\n",
            "0.0    563\n",
            "1.0     74\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_on_ground\n",
            "0.0    324\n",
            "1.0    313\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_percent\n",
            "67.0     143\n",
            "0.0       82\n",
            "38.0      42\n",
            "48.0      38\n",
            "21.0      33\n",
            "50.0      31\n",
            "23.0      29\n",
            "91.0      26\n",
            "137.0     25\n",
            "104.0     24\n",
            "111.0     23\n",
            "100.0     15\n",
            "126.0     12\n",
            "123.0     12\n",
            "115.0     11\n",
            "131.0     10\n",
            "103.0      9\n",
            "130.0      8\n",
            "87.0       8\n",
            "75.0       8\n",
            "66.0       7\n",
            "101.0      7\n",
            "42.0       6\n",
            "9.0        4\n",
            "76.0       4\n",
            "84.0       3\n",
            "107.0      3\n",
            "15.0       2\n",
            "26.0       2\n",
            "24.0       2\n",
            "34.0       2\n",
            "59.0       1\n",
            "28.0       1\n",
            "78.0       1\n",
            "60.0       1\n",
            "3.0        1\n",
            "109.0      1\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_position_x\n",
            "-70.599998    14\n",
            "-55.893166     8\n",
            "-38.799999     7\n",
            "-21.189283     6\n",
            " 64.155830     6\n",
            "              ..\n",
            "-8.211702      1\n",
            "-8.263830      1\n",
            " 0.191919      1\n",
            " 19.078030     1\n",
            " 10.171816     1\n",
            "Name: count, Length: 525, dtype: int64 \n",
            "\n",
            "p1_position_y\n",
            " 0.000100      243\n",
            " 27.200100      46\n",
            " 54.400101      25\n",
            "-16.500000      15\n",
            " 8.850101        6\n",
            "              ... \n",
            " 87.036087       1\n",
            " 71.652084       1\n",
            " 49.350105       1\n",
            " 11.000105       1\n",
            "-110.920013      1\n",
            "Name: count, Length: 256, dtype: int64 \n",
            "\n",
            "p1_shield_strength\n",
            "60.000000    339\n",
            "58.180008      3\n",
            "59.510002      3\n",
            "52.299999      3\n",
            "36.552689      2\n",
            "            ... \n",
            "42.852661      1\n",
            "43.902657      1\n",
            "44.952652      1\n",
            "46.002647      1\n",
            "55.102772      1\n",
            "Name: count, Length: 282, dtype: int64 \n",
            "\n",
            "p1_stock\n",
            "4.0    352\n",
            "3.0    284\n",
            "2.0      1\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_action_frame\n",
            " 1.0     83\n",
            " 2.0     49\n",
            "-1.0     43\n",
            " 4.0     43\n",
            " 3.0     37\n",
            " 5.0     36\n",
            " 7.0     30\n",
            " 6.0     28\n",
            " 11.0    22\n",
            " 16.0    20\n",
            " 9.0     18\n",
            " 29.0    16\n",
            " 8.0     16\n",
            " 14.0    15\n",
            " 13.0    14\n",
            " 15.0    14\n",
            " 17.0    13\n",
            " 20.0    12\n",
            " 10.0    11\n",
            " 12.0    11\n",
            " 19.0    11\n",
            " 21.0    11\n",
            " 18.0    10\n",
            " 22.0     8\n",
            " 24.0     6\n",
            " 0.0      5\n",
            " 23.0     5\n",
            " 30.0     4\n",
            " 31.0     4\n",
            " 26.0     4\n",
            " 25.0     3\n",
            " 34.0     3\n",
            " 27.0     3\n",
            " 32.0     3\n",
            " 45.0     2\n",
            " 46.0     2\n",
            " 47.0     2\n",
            " 35.0     2\n",
            " 28.0     2\n",
            " 42.0     2\n",
            " 39.0     2\n",
            " 60.0     2\n",
            " 36.0     2\n",
            " 57.0     1\n",
            " 43.0     1\n",
            " 38.0     1\n",
            " 40.0     1\n",
            " 55.0     1\n",
            " 41.0     1\n",
            " 49.0     1\n",
            " 33.0     1\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_controller_c_stick_x\n",
            "0.50000    621\n",
            "0.00625      3\n",
            "0.83750      1\n",
            "0.70000      1\n",
            "0.69375      1\n",
            "0.79375      1\n",
            "0.12500      1\n",
            "0.74375      1\n",
            "0.22500      1\n",
            "0.82500      1\n",
            "0.32500      1\n",
            "0.01250      1\n",
            "0.99375      1\n",
            "0.68750      1\n",
            "0.10000      1\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_controller_c_stick_y\n",
            "0.50000    619\n",
            "0.00625      3\n",
            "0.93125      1\n",
            "0.35000      1\n",
            "0.31250      1\n",
            "0.66875      1\n",
            "0.00000      1\n",
            "0.87500      1\n",
            "0.08750      1\n",
            "0.01875      1\n",
            "0.98125      1\n",
            "0.10000      1\n",
            "0.99375      1\n",
            "0.04375      1\n",
            "0.05000      1\n",
            "0.86250      1\n",
            "0.26250      1\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_controller_l_shoulder\n",
            "0.000000    510\n",
            "1.000000    116\n",
            "0.928571      2\n",
            "0.321429      1\n",
            "0.864286      1\n",
            "0.828571      1\n",
            "0.442857      1\n",
            "0.992857      1\n",
            "0.478571      1\n",
            "0.585714      1\n",
            "0.821429      1\n",
            "0.492857      1\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_controller_r_shoulder\n",
            "0.000000    510\n",
            "1.000000    116\n",
            "0.928571      2\n",
            "0.321429      1\n",
            "0.864286      1\n",
            "0.828571      1\n",
            "0.442857      1\n",
            "0.992857      1\n",
            "0.478571      1\n",
            "0.585714      1\n",
            "0.821429      1\n",
            "0.492857      1\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_controller_main_stick_x\n",
            "0.50000    309\n",
            "0.99375    102\n",
            "0.00625     61\n",
            "0.00000     13\n",
            "1.00000      9\n",
            "          ... \n",
            "0.35625      1\n",
            "0.21250      1\n",
            "0.02500      1\n",
            "0.76250      1\n",
            "0.68750      1\n",
            "Name: count, Length: 73, dtype: int64 \n",
            "\n",
            "p3_controller_main_stick_y\n",
            "0.50000    426\n",
            "0.00625     44\n",
            "0.99375     23\n",
            "0.01250      5\n",
            "0.86875      5\n",
            "          ... \n",
            "0.06875      1\n",
            "0.64375      1\n",
            "0.11875      1\n",
            "0.87500      1\n",
            "0.75000      1\n",
            "Name: count, Length: 79, dtype: int64 \n",
            "\n",
            "p3_button_button_a\n",
            "0.0    625\n",
            "1.0     12\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_button_button_b\n",
            "0.0    608\n",
            "1.0     29\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_button_button_x\n",
            "0.0    636\n",
            "1.0      1\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_button_button_y\n",
            "0.0    592\n",
            "1.0     45\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_button_button_z\n",
            "0.0    637\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_button_button_l\n",
            "0.0    637\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_button_button_r\n",
            "0.0    533\n",
            "1.0    104\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_button_button_start\n",
            "0.0    637\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_facing\n",
            "1.0    360\n",
            "0.0    277\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_hitlag_left\n",
            "0.0    637\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_hitstun_frames_left\n",
            "0.0     445\n",
            "1.0       9\n",
            "22.0      8\n",
            "18.0      8\n",
            "20.0      7\n",
            "       ... \n",
            "41.0      1\n",
            "42.0      1\n",
            "35.0      1\n",
            "50.0      1\n",
            "24.0      1\n",
            "Name: count, Length: 65, dtype: int64 \n",
            "\n",
            "p3_jumps_left\n",
            "1.0    277\n",
            "2.0    237\n",
            "0.0    123\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_off_stage\n",
            "0.0    499\n",
            "1.0    138\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_on_ground\n",
            "0.0    400\n",
            "1.0    237\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_percent\n",
            "0.0      116\n",
            "49.0      71\n",
            "88.0      45\n",
            "15.0      40\n",
            "16.0      40\n",
            "71.0      38\n",
            "112.0     26\n",
            "90.0      20\n",
            "78.0      20\n",
            "7.0       19\n",
            "61.0      17\n",
            "101.0     15\n",
            "43.0      13\n",
            "2.0       12\n",
            "30.0      11\n",
            "135.0      9\n",
            "17.0       9\n",
            "133.0      8\n",
            "62.0       8\n",
            "35.0       8\n",
            "140.0      8\n",
            "23.0       7\n",
            "34.0       7\n",
            "123.0      6\n",
            "89.0       6\n",
            "54.0       6\n",
            "76.0       6\n",
            "125.0      5\n",
            "110.0      5\n",
            "113.0      5\n",
            "97.0       4\n",
            "75.0       4\n",
            "95.0       4\n",
            "134.0      4\n",
            "27.0       3\n",
            "24.0       3\n",
            "120.0      1\n",
            "100.0      1\n",
            "79.0       1\n",
            "57.0       1\n",
            "42.0       1\n",
            "10.0       1\n",
            "8.0        1\n",
            "4.0        1\n",
            "36.0       1\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_position_x\n",
            " 40.000000    12\n",
            " 38.799999     7\n",
            "-82.987198     6\n",
            " 28.393167     6\n",
            " 40.509720     5\n",
            "              ..\n",
            "-68.848976     1\n",
            "-59.865517     1\n",
            "-47.274967     1\n",
            "-31.007961     1\n",
            "-68.522667     1\n",
            "Name: count, Length: 546, dtype: int64 \n",
            "\n",
            "p3_position_y\n",
            " 0.000100     180\n",
            " 27.200100     41\n",
            " 54.400101     17\n",
            " 9.730101       9\n",
            " 0.000100       9\n",
            "             ... \n",
            " 43.807503      1\n",
            " 39.547512      1\n",
            " 6.139729       1\n",
            " 20.372810      1\n",
            "-99.343819      1\n",
            "Name: count, Length: 327, dtype: int64 \n",
            "\n",
            "p3_shield_strength\n",
            "60.000000    436\n",
            "54.399986      3\n",
            "56.499977      2\n",
            "57.549973      2\n",
            "53.349991      2\n",
            "            ... \n",
            "57.383980      1\n",
            "58.433975      1\n",
            "59.483971      1\n",
            "50.480019      1\n",
            "59.507977      1\n",
            "Name: count, Length: 185, dtype: int64 \n",
            "\n",
            "p3_stock\n",
            "1.0    227\n",
            "2.0    164\n",
            "4.0    148\n",
            "3.0     98\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "stage\n",
            "24.0    637\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p1_action\n",
            "67.0     40\n",
            "90.0     35\n",
            "24.0     32\n",
            "25.0     30\n",
            "42.0     24\n",
            "         ..\n",
            "224.0     1\n",
            "23.0      1\n",
            "75.0      1\n",
            "85.0      1\n",
            "322.0     1\n",
            "Name: count, Length: 93, dtype: int64 \n",
            "\n",
            "p1_character\n",
            "22.0    637\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "p3_action\n",
            "90.0     39\n",
            "69.0     38\n",
            "27.0     33\n",
            "88.0     29\n",
            "42.0     26\n",
            "         ..\n",
            "363.0     1\n",
            "23.0      1\n",
            "89.0      1\n",
            "40.0      1\n",
            "235.0     1\n",
            "Name: count, Length: 90, dtype: int64 \n",
            "\n",
            "p3_character\n",
            "22.0    637\n",
            "Name: count, dtype: int64 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for column in df.columns:\n",
        "    print(df[column].value_counts(), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OicXXgs3KU3N",
      "metadata": {
        "id": "OicXXgs3KU3N"
      },
      "source": [
        "# Define Constants and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "EHxwlNSwKgqj",
      "metadata": {
        "id": "EHxwlNSwKgqj"
      },
      "outputs": [],
      "source": [
        "DATA_FOLDER_PATH = \"./training_data\"\n",
        "NUM_ENUM_COLUMNS = 5  # Last 5 columns of the numpy arrays"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lJufwHhwIHtH",
      "metadata": {
        "id": "lJufwHhwIHtH"
      },
      "source": [
        "# Data Loading and Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "5f93ab1b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib\n",
        "import data_loading\n",
        "import models\n",
        "importlib.reload(data_loading) \n",
        "importlib.reload(models)\n",
        "from models import MeleeEncoderDecoder, EnumEmbeddingModule \n",
        "from data_loading import BatchedFilesDataset, MeleeDataset\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "12c194d7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total non-numeric columns found: 0\n",
            "Non-numeric column names: []\n"
          ]
        }
      ],
      "source": [
        "# Load the data\n",
        "data = np.load(\"./training_data/(...) Falco vs Falco (BABE) [BF] Game_20200122T213211_sequences.npz\", allow_pickle=True)\n",
        "inputs = data['inputs']\n",
        "\n",
        "# Find columns with non-numeric data\n",
        "non_numeric_cols = []\n",
        "for col in columns:\n",
        "    if not np.issubdtype(df[col].dtype, np.number):\n",
        "        print(f\"Column '{col}' has non-numeric type: {df[col].dtype}\")\n",
        "        print(f\"Sample values: {df[col].head()}\\n\")\n",
        "        non_numeric_cols.append(col)\n",
        "\n",
        "print(f\"\\nTotal non-numeric columns found: {len(non_numeric_cols)}\")\n",
        "print(f\"Non-numeric column names: {non_numeric_cols}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "001e3e48",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From tensor: torch.Size([623, 10, 5])\n",
            "From tensor: torch.Size([623, 5, 5])\n"
          ]
        }
      ],
      "source": [
        "dataset = MeleeDataset(data_path=\"./training_data/(...) Falco vs Falco (BABE) [BF] Game_20200122T213211_sequences.npz\", match_id=0, num_enums=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "VPj87EHMcOZa",
      "metadata": {
        "id": "VPj87EHMcOZa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From tensor: torch.Size([690, 10, 5])\n",
            "From tensor: torch.Size([690, 5, 5])\n",
            "Loaded ./training_data/(...) Falco vs Falco (BABE) [DL] Game_20200122T213501_sequences.npz\n",
            "[<data_loading.MeleeDataset object at 0x15ef9ba30>]\n",
            "From tensor: torch.Size([623, 10, 5])\n",
            "From tensor: torch.Size([623, 5, 5])\n",
            "Loaded ./training_data/(...) Falco vs Falco (BABE) [BF] Game_20200122T213211_sequences.npz\n",
            "[<data_loading.MeleeDataset object at 0x15f2ddea0>]\n"
          ]
        }
      ],
      "source": [
        "batched_files = BatchedFilesDataset(DATA_FOLDER_PATH, files_per_batch=1)\n",
        "\n",
        "batched_files.load_next_batch()\n",
        "dataloader = DataLoader(batched_files.load_next_batch(), batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "qij_9UqRcQ1E",
      "metadata": {
        "id": "qij_9UqRcQ1E"
      },
      "outputs": [],
      "source": [
        "# model = MeleeEncoderDecoder(feature_dim=dataset.inputs.shape[-1])\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "# loss_fn = nn.MSELoss()\n",
        "\n",
        "# for epoch in range(10):\n",
        "#     model.train()\n",
        "#     total_loss = 0\n",
        "\n",
        "#     for x_batch, y_batch in dataloader: # frames 10-19, and 20-24\n",
        "#         decoder_input = y_batch[:, :-1, :]  # teacher forcing; grabs everything up until the last frame of the sequence, 20-23\n",
        "#         decoder_target = y_batch[:, 1:, :]  # grabs everything after the 1st frame, 21-24\n",
        "\n",
        "#         preds = model(x_batch, decoder_input) # given frames 10-19 and the decoder input of 20-23, output is which frames?\n",
        "\n",
        "#         loss = loss_fn(preds, decoder_target)\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         total_loss += loss.item()\n",
        "\n",
        "#     print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "NisMEGa6_p3P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "NisMEGa6_p3P",
        "outputId": "0054ba91-8805-4b50-e658-3aeb00cad6af"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import wandb\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Define enum dimensions (vocabulary sizes for each categorical feature)\n",
        "enum_dims = {\n",
        "    'stage': 32,           # Number of possible stages\n",
        "    'p1_action': 386,      # Number of possible actions\n",
        "    'p1_character': 26,    # Number of possible characters\n",
        "    'p2_action': 386,      # Number of possible actions\n",
        "    'p2_character': 26     # Number of possible characters\n",
        "}\n",
        "\n",
        "# Define embedding dimensions for each enum feature\n",
        "embedding_dims = {\n",
        "    'stage': 16,          # Embedding dimension for stages\n",
        "    'p1_action': 64,      # Embedding dimension for actions\n",
        "    'p1_character': 16,   # Embedding dimension for characters\n",
        "    'p2_action': 64,      # Embedding dimension for actions\n",
        "    'p2_character': 16    # Embedding dimension for characters\n",
        "}\n",
        "\n",
        "def train_model(\n",
        "    data_folder: str,\n",
        "    model_save_path: str,\n",
        "    batch_size: int = 32,\n",
        "    num_epochs: int = 20,\n",
        "    learning_rate: float = 1e-4,\n",
        "    files_per_batch: int = 1,\n",
        "    num_enums: int = 5,\n",
        "    d_model: int = 128,\n",
        "    nhead: int = 4,\n",
        "    num_layers: int = 3,\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "):\n",
        "    # Initialize dataset\n",
        "    dataset = BatchedFilesDataset(\n",
        "        data_folder=data_folder,\n",
        "        files_per_batch=files_per_batch,\n",
        "    )\n",
        "\n",
        "    # Get first batch to determine dimensions\n",
        "    first_batch = dataset.load_next_batch()\n",
        "    continuous_dim = first_batch[0]['continuous_inputs'].shape[-1] - num_enums  # Update if needed\n",
        "\n",
        "    # Rest of the code remains the same...\n",
        "    # Initialize model\n",
        "    model = MeleeEncoderDecoder(\n",
        "        continuous_dim=continuous_dim,\n",
        "        enum_dims=enum_dims,\n",
        "        embedding_dims=embedding_dims,\n",
        "        d_model=d_model,\n",
        "        nhead=nhead,\n",
        "        num_layers=num_layers\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=2\n",
        "    )\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    # Initialize wandb\n",
        "    wandb.init(\n",
        "        project=\"melee_prediction\",\n",
        "        config={\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"epochs\": num_epochs,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"continuous_dim\": continuous_dim,\n",
        "            \"enum_dims\": enum_dims,\n",
        "            \"embedding_dims\": embedding_dims,\n",
        "            \"d_model\": d_model,\n",
        "            \"nhead\": nhead,\n",
        "            \"num_layers\": num_layers,\n",
        "            \"model_type\": model.__class__.__name__\n",
        "        }\n",
        "    )\n",
        "    wandb.watch(model, log=\"all\", log_freq=100)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        batch_dataset = dataset.load_next_batch()\n",
        "\n",
        "        continuous_inputs_list = []\n",
        "        continuous_targets_list = []\n",
        "        enum_inputs_dict = {name: [] for name in enum_dims.keys()}\n",
        "        enum_targets_dict = {name: [] for name in enum_dims.keys()}\n",
        "\n",
        "        for batch in batch_dataset:\n",
        "            # Collect continuous data\n",
        "            continuous_inputs_list.append(batch['continuous_inputs'])\n",
        "            continuous_targets_list.append(batch['continuous_targets'])\n",
        "            \n",
        "            # Collect enum data\n",
        "            for name in enum_dims.keys():\n",
        "                enum_inputs_dict[name].append(batch[name])\n",
        "                enum_targets_dict[name].append(batch[f'target_{name}'])\n",
        "\n",
        "        # Stack all tensors\n",
        "        x_continuous = torch.stack(continuous_inputs_list, dim=0).to(device)\n",
        "        y_continuous = torch.stack(continuous_targets_list, dim=0).to(device)\n",
        "        \n",
        "        x_enums = {name: torch.stack(tensors, dim=0).to(device) \n",
        "                  for name, tensors in enum_inputs_dict.items()}\n",
        "        y_enums = {name: torch.stack(tensors, dim=0).to(device) \n",
        "                  for name, tensors in enum_targets_dict.items()}\n",
        "\n",
        "        # Teacher forcing setup\n",
        "        decoder_continuous_input = y_continuous[:, :-1, :]\n",
        "        decoder_continuous_target = y_continuous[:, 1:, :]\n",
        "        \n",
        "        decoder_enum_input = {name: tensor[:, :-1, :] for name, tensor in y_enums.items()}\n",
        "        decoder_enum_target = {name: tensor[:, 1:, :] for name, tensor in y_enums.items()}\n",
        "\n",
        "        # Forward pass\n",
        "        continuous_pred, enum_preds = model(\n",
        "            x_continuous, \n",
        "            x_enums,\n",
        "            decoder_continuous_input,\n",
        "            decoder_enum_input\n",
        "        )\n",
        "\n",
        "        # Use model's compute_loss method\n",
        "        total_batch_loss, loss_components = model.compute_loss(\n",
        "            cont_preds=continuous_pred,\n",
        "            enum_preds=enum_preds,\n",
        "            cont_targets=decoder_continuous_target,\n",
        "            enum_targets=decoder_enum_target\n",
        "        )\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        total_batch_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += total_batch_loss.item()\n",
        "        batch_count += 1\n",
        "        avg_loss = total_loss / batch_count\n",
        "\n",
        "        # Logging\n",
        "        log_dict = {\n",
        "            \"batch_loss\": total_batch_loss.item(),\n",
        "            \"continuous_loss\": loss_components[\"continuous\"].item(),\n",
        "            \"avg_loss\": avg_loss,\n",
        "            \"learning_rate\": optimizer.param_groups[0][\"lr\"]\n",
        "            \n",
        "        }\n",
        "        # Add individual enum losses to logging\n",
        "        for name, loss in loss_components.items():\n",
        "            if name != \"continuous\":\n",
        "                log_dict[f\"{name}_loss\"] = loss.item()\n",
        "                \n",
        "        wandb.log(log_dict)\n",
        "\n",
        "        scheduler.step(avg_loss)\n",
        "\n",
        "        # Save checkpoints\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            checkpoint_path = Path(model_save_path) / f\"checkpoint_epoch_{epoch + 1}.pt\"\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': avg_loss,\n",
        "            }, checkpoint_path)\n",
        "\n",
        "    # Save final model\n",
        "    torch.save(model.state_dict(), os.path.join(model_save_path, \"melee_predictor.pt\"))\n",
        "    wandb.finish()\n",
        "    \n",
        "\n",
        "def run_inference(\n",
        "    model_path: str,\n",
        "    continuous_input: torch.Tensor,\n",
        "    enum_inputs,  # Dict[str, torch.Tensor],\n",
        "    num_frames: int = 5,\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "):\n",
        "    \"\"\"Run inference to predict future frames.\"\"\"\n",
        "    # Load model with same architecture as training\n",
        "    model = MeleeEncoderDecoder(\n",
        "        continuous_dim=continuous_input.shape[-1],\n",
        "        enum_dims=enum_dims,  # Define these based on your data\n",
        "        embedding_dims=embedding_dims,  # Define these based on your data\n",
        "        d_model=128,\n",
        "        nhead=4,\n",
        "        num_layers=3\n",
        "    ).to(device)\n",
        "    \n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Prepare inputs\n",
        "        continuous_seq = continuous_input.unsqueeze(0).to(device)\n",
        "        enum_seqs = {name: tensor.unsqueeze(0).to(device) \n",
        "                    for name, tensor in enum_inputs.items()}\n",
        "        \n",
        "        # Initialize decoder inputs\n",
        "        decoder_continuous = torch.zeros(\n",
        "            (1, 1, continuous_input.shape[-1]), \n",
        "            device=device\n",
        "        )\n",
        "        decoder_enums = {\n",
        "            name: torch.zeros((1, 1, dim), device=device)\n",
        "            for name, dim in enum_dims.items()\n",
        "        }\n",
        "\n",
        "        continuous_predictions = []\n",
        "        enum_predictions = {name: [] for name in enum_dims.keys()}\n",
        "\n",
        "        for _ in range(num_frames):\n",
        "            # Get next frame prediction\n",
        "            cont_out, enum_outs = model(\n",
        "                continuous_seq,\n",
        "                enum_seqs,\n",
        "                decoder_continuous,\n",
        "                decoder_enums\n",
        "            )\n",
        "            \n",
        "            # Get last frame predictions\n",
        "            next_continuous = cont_out[:, -1:, :]\n",
        "            next_enums = {name: pred[:, -1:, :] for name, pred in enum_outs.items()}\n",
        "            \n",
        "            # Store predictions\n",
        "            continuous_predictions.append(next_continuous)\n",
        "            for name, pred in next_enums.items():\n",
        "                enum_predictions[name].append(pred)\n",
        "            \n",
        "            # Update decoder inputs\n",
        "            decoder_continuous = torch.cat([decoder_continuous, next_continuous], dim=1)\n",
        "            decoder_enums = {\n",
        "                name: torch.cat([decoder_enums[name], next_enum], dim=1)\n",
        "                for name, next_enum in next_enums.items()\n",
        "            }\n",
        "\n",
        "        # Combine all predictions\n",
        "        continuous_result = torch.cat(continuous_predictions, dim=1).squeeze(0)\n",
        "        enum_results = {\n",
        "            name: torch.cat(preds, dim=1).squeeze(0)\n",
        "            for name, preds in enum_predictions.items()\n",
        "        }\n",
        "        \n",
        "        return continuous_result, enum_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "b5c4009c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Access the Wandb API key\n",
        "wandb_api_key = os.environ.get(\"WANDB_API_KEY\")\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "eea9e931",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/alexoon/Desktop/smash_bot/smash_venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From tensor: torch.Size([690, 10, 5])\n",
            "From tensor: torch.Size([690, 5, 5])\n",
            "Loaded ./training_data/(...) Falco vs Falco (BABE) [DL] Game_20200122T213501_sequences.npz\n",
            "[<data_loading.MeleeDataset object at 0x13f6d6410>]\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">wild-planet-7</strong> at: <a href='https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction/runs/i61q6okz' target=\"_blank\">https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction/runs/i61q6okz</a><br> View project at: <a href='https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction' target=\"_blank\">https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250421_222511-i61q6okz/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/alexoon/Desktop/smash_bot/icl_smash/wandb/run-20250421_223255-evddv367</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction/runs/evddv367' target=\"_blank\">effortless-sun-8</a></strong> to <a href='https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction' target=\"_blank\">https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction/runs/evddv367' target=\"_blank\">https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction/runs/evddv367</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From tensor: torch.Size([623, 10, 5])\n",
            "From tensor: torch.Size([623, 5, 5])\n",
            "Loaded ./training_data/(...) Falco vs Falco (BABE) [BF] Game_20200122T213211_sequences.npz\n",
            "[<data_loading.MeleeDataset object at 0x15eeb3430>]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (6230x54 and 225x128)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[53], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m MODEL_SAVE_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/icl_smash-main/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;66;03m#\"/content/drive/MyDrive/Berkeley Classes/sp25/CS182/icl_smash-main/melee_predictor.pt\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATA_FOLDER_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_SAVE_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[51], line 124\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data_folder, model_save_path, batch_size, num_epochs, learning_rate, files_per_batch, num_enums, d_model, nhead, num_layers, device)\u001b[0m\n\u001b[1;32m    121\u001b[0m decoder_enum_target \u001b[38;5;241m=\u001b[39m {name: tensor[:, \u001b[38;5;241m1\u001b[39m:, :] \u001b[38;5;28;01mfor\u001b[39;00m name, tensor \u001b[38;5;129;01min\u001b[39;00m y_enums\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m continuous_pred, enum_preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_continuous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_enums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_continuous_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_enum_input\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Use model's compute_loss method\u001b[39;00m\n\u001b[1;32m    132\u001b[0m total_batch_loss, loss_components \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcompute_loss(\n\u001b[1;32m    133\u001b[0m     cont_preds\u001b[38;5;241m=\u001b[39mcontinuous_pred,\n\u001b[1;32m    134\u001b[0m     enum_preds\u001b[38;5;241m=\u001b[39menum_preds,\n\u001b[1;32m    135\u001b[0m     cont_targets\u001b[38;5;241m=\u001b[39mdecoder_continuous_target,\n\u001b[1;32m    136\u001b[0m     enum_targets\u001b[38;5;241m=\u001b[39mdecoder_enum_target\n\u001b[1;32m    137\u001b[0m )\n",
            "File \u001b[0;32m~/Desktop/smash_bot/smash_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/smash_bot/smash_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1845\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1850\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
            "File \u001b[0;32m~/Desktop/smash_bot/smash_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1793\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1790\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1791\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1793\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1796\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1797\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1798\u001b[0m     ):\n\u001b[1;32m   1799\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/smash_bot/icl_smash/models.py:108\u001b[0m, in \u001b[0;36mMeleeEncoderDecoder.forward\u001b[0;34m(self, src_cont, src_enum, tgt_cont, tgt_enum)\u001b[0m\n\u001b[1;32m    105\u001b[0m tgt_enum_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menum_embedder(tgt_enum)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Step 2: Concatenate continuous + enum embeddings\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_cont\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m tgt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_proj(tgt_cont)\n\u001b[1;32m    110\u001b[0m src \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([src_cont, src_enum_embed], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m~/Desktop/smash_bot/smash_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/smash_bot/smash_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/Desktop/smash_bot/smash_venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (6230x54 and 225x128)"
          ]
        }
      ],
      "source": [
        "MODEL_SAVE_PATH = \"/content/drive/MyDrive/icl_smash-main/\"#\"/content/drive/MyDrive/Berkeley Classes/sp25/CS182/icl_smash-main/melee_predictor.pt\"\n",
        "\n",
        "# Training\n",
        "train_model(\n",
        "    data_folder=DATA_FOLDER_PATH,\n",
        "    model_save_path=MODEL_SAVE_PATH,\n",
        "    batch_size=32,\n",
        "    num_epochs=20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AhExU6UIcSrj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhExU6UIcSrj",
        "outputId": "86642789-4c52-4227-c56e-1a2acb55b7a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5, 119)\n"
          ]
        }
      ],
      "source": [
        "# import torch\n",
        "\n",
        "# # suppose you still have y_mean, y_std from training,\n",
        "# # both of shape (feature_dim,)\n",
        "# # and you moved them to the same device as your model:\n",
        "\n",
        "# device    = next(model.parameters()).device\n",
        "# y_mean    = y_mean.to(device)    # shape (feature_dim,)\n",
        "# y_std     = y_std.to(device)     # shape (feature_dim,)\n",
        "\n",
        "# model.eval()\n",
        "# with torch.no_grad():\n",
        "#     # grab one test input\n",
        "#     input_seq = dataset.inputs[-1].unsqueeze(0).to(device)  # (1, in_len, feat_dim)\n",
        "#     # start decoder with one “zero” frame\n",
        "#     decoder_input = torch.zeros((1, 1, dataset.inputs.shape[-1]),\n",
        "#                                 device=device)\n",
        "\n",
        "#     preds_norm = []\n",
        "#     for _ in range(5):\n",
        "#         out = model(input_seq, decoder_input)     # (1, cur_tgt_len, feat_dim)\n",
        "#         next_step = out[:, -1:, :]                # (1, 1, feat_dim)\n",
        "#         preds_norm.append(next_step)\n",
        "#         decoder_input = torch.cat([decoder_input, next_step], dim=1)\n",
        "\n",
        "#     preds_norm = torch.cat(preds_norm, dim=1)     # (1, 5, feat_dim)\n",
        "\n",
        "#     # --- Undo the scaling ---\n",
        "#     # reshape mean/std to broadcast over (batch, time, feature)\n",
        "#     mu = y_mean.view(1, 1, -1)    # (1,1,feat_dim)\n",
        "#     sigma = y_std.view(1, 1, -1)  # (1,1,feat_dim)\n",
        "\n",
        "#     preds_denorm = preds_norm * sigma + mu      # (1, 5, feat_dim)\n",
        "\n",
        "#     # now preds_denorm is in the original units\n",
        "#     # you can convert to NumPy if you like:\n",
        "#     preds_denorm = preds_denorm.squeeze(0).cpu().numpy()  # (5, feat_dim)\n",
        "\n",
        "# print(preds_denorm.shape)  # e.g. (5, feat_dim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1475e85a",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7df1dd9",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7146ff96",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "smash_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
