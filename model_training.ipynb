{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "64c0R3AxHwDi",
      "metadata": {
        "id": "64c0R3AxHwDi"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "Ts_F_w3UrVJf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts_F_w3UrVJf",
        "outputId": "2a8e95de-e75b-492b-cb98-1a8aeca5be6b"
      },
      "outputs": [],
      "source": [
        "# !CFLAGS=\"-I/usr/include\" LDFLAGS=\"-L/usr/lib -lenet\" pip install pyenet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "lnlRj3Vuratw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnlRj3Vuratw",
        "outputId": "f280d7d8-03d7-4a54-932a-82c86b0d99f5"
      },
      "outputs": [],
      "source": [
        "# !pip install git+https://github.com/vladfi1/libmelee.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "zr0RXPKlq1h1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr0RXPKlq1h1",
        "outputId": "bd842a04-01a3-480b-e136-d5b40bcf6f8a"
      },
      "outputs": [],
      "source": [
        "# !apt-get update\n",
        "# !apt-get install -y cmake libenet-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "jLZkYNFSryl4",
      "metadata": {
        "id": "jLZkYNFSryl4"
      },
      "outputs": [],
      "source": [
        "# !pip install peppi_py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "qebqN1Qyt35W",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "qebqN1Qyt35W",
        "outputId": "4eb27cdc-dd1f-469a-8089-3ae90f013958"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "608918b2",
      "metadata": {
        "id": "608918b2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import melee\n",
        "import numpy as np\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, ConcatDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bED8qxv1IBxZ",
      "metadata": {
        "id": "bED8qxv1IBxZ"
      },
      "source": [
        "# Data Processing (Deprecated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d785e7e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "d785e7e7",
        "outputId": "b5f30004-bccc-4acb-e4e7-df207b23ad2c"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mgetcwd()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5b2c63b2",
      "metadata": {
        "id": "5b2c63b2"
      },
      "outputs": [],
      "source": [
        "# console = melee.Console(is_dolphin=False,\n",
        "#                         allow_old_version=False,\n",
        "#                         path=\"./data/BTSSmash-Game_20200126T202356.slp\"\n",
        "#                         )\n",
        "# console.connect()\n",
        "\n",
        "# while True:\n",
        "#     gamestate = console.step()\n",
        "#     # step() returns None when the file ends\n",
        "#     if gamestate is None:\n",
        "#         break\n",
        "#     print(\"Frame \" + str(gamestate.frame))\n",
        "#     for _, player in gamestate.players.items():\n",
        "#         print(\"\\t\", player.stock, player.percent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f5233e87",
      "metadata": {
        "id": "f5233e87"
      },
      "outputs": [],
      "source": [
        "# import peppi_py as peppi\n",
        "# import numpy as np\n",
        "\n",
        "# def get_numpy_row(pre, post):\n",
        "#     def safe_extract(val):\n",
        "#         return val.to_numpy() # if val is not None else np.nan\n",
        "\n",
        "#     features = []\n",
        "\n",
        "#     # --- Pre ---\n",
        "#     features += [\n",
        "#         safe_extract(pre.position.x),\n",
        "#         safe_extract(pre.position.y),\n",
        "#         safe_extract(pre.joystick.x),\n",
        "#         safe_extract(pre.joystick.y),\n",
        "#         safe_extract(pre.triggers),\n",
        "#         safe_extract(pre.buttons),\n",
        "#         safe_extract(pre.buttons_physical),\n",
        "#         safe_extract(pre.direction),\n",
        "#         safe_extract(pre.percent) if pre.percent else np.nan\n",
        "#     ]\n",
        "\n",
        "#     # --- Post ---\n",
        "#     features += [\n",
        "#         safe_extract(post.position.x),\n",
        "#         safe_extract(post.position.y),\n",
        "#         safe_extract(post.percent),\n",
        "#         safe_extract(post.shield),\n",
        "#         safe_extract(post.combo_count),\n",
        "#         safe_extract(post.state),\n",
        "#         safe_extract(post.airborne) if post.airborne else np.nan,\n",
        "#         safe_extract(post.stocks),\n",
        "#         safe_extract(post.last_hit_by),\n",
        "#         safe_extract(post.character),\n",
        "#         safe_extract(post.direction),\n",
        "#     ]\n",
        "\n",
        "#     return features\n",
        "\n",
        "# def slp_to_numpy(path, num_ports=2):\n",
        "#     game = peppi.read_slippi(path)\n",
        "#     rows = []\n",
        "\n",
        "#     for port in range(num_ports):\n",
        "#         frame = game.frames\n",
        "#         try:\n",
        "#             pre = frame.ports[port].leader.pre\n",
        "#             post = frame.ports[port].leader.post\n",
        "#             row = get_numpy_row(pre, post)\n",
        "#             rows.append(row)\n",
        "#         except Exception:\n",
        "#             # If frame/port is missing or broken, skip or pad\n",
        "#             rows.append([np.nan] * 20)\n",
        "\n",
        "#     arr = np.array(rows)\n",
        "#     # transpose to (12158, 2, 20)\n",
        "#     arr = arr.transpose(2, 0, 1)\n",
        "#     return arr.reshape(arr.shape[0], -1)\n",
        "\n",
        "# # Example usage\n",
        "# np_data = slp_to_numpy(\"./drive/MyDrive/icl_smash-main/data/Stream-Game_20220828T225335.slp\")\n",
        "# print(\"Shape:\", np_data.shape)\n",
        "# print(np_data[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4c2d7b3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "4c2d7b3a",
        "outputId": "f2cc8e48-17c1-46d5-eac6-36002074bd84"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'np_data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-83432d0159f7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_data.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np_data' is not defined"
          ]
        }
      ],
      "source": [
        "np.save(\"training_data.npy\", np_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rnopVWDkBcNs",
      "metadata": {
        "id": "rnopVWDkBcNs"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from collections import defaultdict\n",
        "# import json\n",
        "\n",
        "# ### Step 0: Load Raw Data ###\n",
        "# raw_data = np.load('./drive/MyDrive/icl_smash-main/training_data/[libmelee]example1_sampled.npy', allow_pickle=True)\n",
        "\n",
        "# ### Step 1: Flatten a Single Frame ###\n",
        "# def flatten_frame(frame):\n",
        "#     flat = {}\n",
        "#     for i, item in enumerate(frame):\n",
        "#         key = f\"col_{i}\"\n",
        "#         if isinstance(item, dict):  # like <Button.BUTTON_A: 'A'>: True\n",
        "#             for k, v in item.items():\n",
        "#                 new_key = f\"{key}_{str(k)}\"\n",
        "#                 flat[new_key] = float(v) if isinstance(v, bool) else v\n",
        "#         else:\n",
        "#             flat[key] = item\n",
        "#     return flat\n",
        "\n",
        "# ### Step 2: Flatten Entire Dataset ###\n",
        "# flat_data = [flatten_frame(frame) for frame in raw_data]\n",
        "\n",
        "# ### Step 3: Build Vocab for Categorical/String Fields ###\n",
        "# def build_vocab(flat_data):\n",
        "#     vocab = defaultdict(set)\n",
        "#     for row in flat_data:\n",
        "#         for k, v in row.items():\n",
        "#             if isinstance(v, str) or str(v) == 'nan':\n",
        "#                 vocab[k].add(v)\n",
        "#     return {k: {val: i for i, val in enumerate(sorted(list(vals)))} for k, vals in vocab.items()}\n",
        "\n",
        "# vocab = build_vocab(flat_data)\n",
        "\n",
        "# ### Step 4: Encode Each Frame to Numeric ###\n",
        "# def encode_flat_row(row, vocab):\n",
        "#     encoded = []\n",
        "#     for k, v in row.items():\n",
        "#         if k in vocab:\n",
        "#             encoded.append(vocab[k].get(v, 0))\n",
        "#         else:\n",
        "#             try:\n",
        "#                 encoded.append(float(v))\n",
        "#             except:\n",
        "#                 encoded.append(0.0)\n",
        "#     return encoded\n",
        "\n",
        "# encoded_data = np.array([encode_flat_row(row, vocab) for row in flat_data], dtype=np.float32)\n",
        "# print(f\"Encoded data shape: {encoded_data.shape}\")  # Should be (842, <num_features>)\n",
        "\n",
        "# ### Step 5: Sliding Window to Create Sequences ###\n",
        "# def create_sequences(data, input_len=10, target_len=5):\n",
        "#     input_seqs = []\n",
        "#     target_seqs = []\n",
        "#     for t in range(len(data) - input_len - target_len): # TODO: Currently slides 1 timestep at a time, but if we are going to infer M of them, can have the inferred M be the last M frames in the next window input\n",
        "#         input_seqs.append(data[t : t + input_len]) # say, frames 10-19, t=10\n",
        "#         target_seqs.append(data[t + input_len : t + input_len + target_len]) # say, frames 20-24, target_len = 5\n",
        "#     return np.array(input_seqs), np.array(target_seqs)\n",
        "\n",
        "# input_len = 10\n",
        "# target_len = 5\n",
        "# input_seqs, target_seqs = create_sequences(encoded_data, input_len, target_len)\n",
        "\n",
        "# print(\"Input shape:\", input_seqs.shape)     # (num_samples, 10, num_features)\n",
        "# print(\"Target shape:\", target_seqs.shape)   # (num_samples, 5, num_features)\n",
        "\n",
        "# ### Step 6 (Optional): Save Output ###\n",
        "# np.save(\"melee_input_seqs.npy\", input_seqs)\n",
        "# np.save(\"melee_target_seqs.npy\", target_seqs)\n",
        "\n",
        "# # Save vocab so you can decode predictions later\n",
        "# with open(\"melee_vocab.json\", \"w\") as f:\n",
        "#     json.dump({k: dict(v) for k, v in vocab.items()}, f)\n",
        "\n",
        "# print(\"âœ… Preprocessing complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45e609b0",
      "metadata": {},
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d65770c1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(637, 59)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import melee\n",
        "import numpy as np\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, ConcatDataset\n",
        "import pandas as pd\n",
        "import importlib\n",
        "import data_processing\n",
        "importlib.reload(data_processing)\n",
        "from data_processing import main\n",
        "main(\"./data/(...) Falco vs Falco (BABE) [BF] Game_20200122T213211.slp\", \"./old_data\", \"viewable\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "759e2496",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame shape: (623, 59)\n",
            "\n",
            "Columns: ['0: frame', '1: distance', '2: p1_action_frame', '3: p1_controller_c_stick_x', '4: p1_controller_c_stick_y', '5: p1_controller_l_shoulder (has a range)', '6: p1_controller_r_shoulder (has a range)', '7: p1_controller_main_stick_x', '8: p1_controller_main_stick_y', '9: p1_button_button_a', '10: p1_button_button_b', '11: p1_button_button_x', '12: p1_button_button_y', '13: p1_button_button_z', '14: p1_button_button_l (0 or 1)', '15: p1_button_button_r (0 or 1)', '16: p1_button_button_start', '17: p1_facing', '18: p1_hitlag_left', '19: p1_hitstun_frames_left', '20: p1_jumps_left', '21: p1_off_stage', '22: p1_on_ground', '23: p1_percent', '24: p1_position_x', '25: p1_position_y', '26: p1_shield_strength', '27: p1_stock', '28: p3_action_frame', '29: p3_controller_c_stick_x', '30: p3_controller_c_stick_y', '31: p3_controller_l_shoulder', '32: p3_controller_r_shoulder', '33: p3_controller_main_stick_x', '34: p3_controller_main_stick_y', '35: p3_button_button_a', '36: p3_button_button_b', '37: p3_button_button_x', '38: p3_button_button_y', '39: p3_button_button_z', '40: p3_button_button_l', '41: p3_button_button_r', '42: p3_button_button_start', '43: p3_facing', '44: p3_hitlag_left', '45: p3_hitstun_frames_left', '46: p3_jumps_left', '47: p3_off_stage', '48: p3_on_ground', '49: p3_percent', '50: p3_position_x', '51: p3_position_y', '52: p3_shield_strength', '53: p3_stock', '54: stage', '55: p1_action', '56: p1_character', '57: p3_action', '58: p3_character']\n",
            "\n",
            "First few rows:\n",
            "   0: frame  1: distance  2: p1_action_frame  3: p1_controller_c_stick_x  \\\n",
            "0    -123.0          0.0                -1.0                         0.5   \n",
            "1    -108.0          0.0                11.0                         0.5   \n",
            "2     -93.0          0.0                11.0                         0.5   \n",
            "3     -78.0          0.0                -1.0                         0.5   \n",
            "4     -63.0          0.0                -1.0                         0.5   \n",
            "\n",
            "   4: p1_controller_c_stick_y  5: p1_controller_l_shoulder (has a range)  \\\n",
            "0                         0.5                                        0.0   \n",
            "1                         0.5                                        0.0   \n",
            "2                         0.5                                        0.0   \n",
            "3                         0.5                                        0.0   \n",
            "4                         0.5                                        0.0   \n",
            "\n",
            "   6: p1_controller_r_shoulder (has a range)  7: p1_controller_main_stick_x  \\\n",
            "0                                        0.0                            0.5   \n",
            "1                                        0.0                            0.5   \n",
            "2                                        0.0                            0.5   \n",
            "3                                        0.0                            0.5   \n",
            "4                                        0.0                            0.5   \n",
            "\n",
            "   8: p1_controller_main_stick_y  9: p1_button_button_a  ...  49: p3_percent  \\\n",
            "0                            0.5                    0.0  ...             0.0   \n",
            "1                            0.5                    0.0  ...             0.0   \n",
            "2                            0.5                    0.0  ...             0.0   \n",
            "3                            0.5                    0.0  ...             0.0   \n",
            "4                            0.5                    0.0  ...             0.0   \n",
            "\n",
            "   50: p3_position_x  51: p3_position_y  52: p3_shield_strength  53: p3_stock  \\\n",
            "0          38.799999          35.200001                    60.0           4.0   \n",
            "1          38.799999          35.242424                    60.0           4.0   \n",
            "2          38.799999          35.878796                    60.0           4.0   \n",
            "3          38.799999          36.430321                    60.0           4.0   \n",
            "4          38.799999          35.793949                    60.0           4.0   \n",
            "\n",
            "   54: stage  55: p1_action  56: p1_character  57: p3_action  58: p3_character  \n",
            "0       24.0          322.0              22.0          322.0              22.0  \n",
            "1       24.0          323.0              22.0          323.0              22.0  \n",
            "2       24.0          323.0              22.0          323.0              22.0  \n",
            "3       24.0          324.0              22.0          324.0              22.0  \n",
            "4       24.0          324.0              22.0          324.0              22.0  \n",
            "\n",
            "[5 rows x 59 columns]\n"
          ]
        }
      ],
      "source": [
        "# Load viewable data and columns\n",
        "viewable_data = np.load(\"./training_data/(...) Falco vs Falco (BABE) [BF] Game_20200122T213211_sequences.npz\", allow_pickle=True)['inputs'][:, 0, :]\n",
        "\n",
        "with open('./training_data/(...) Falco vs Falco (BABE) [BF] Game_20200122T213211_columns.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "columns = text.split(\"\\n\")[:-1]\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(viewable_data.astype('float32'), columns=columns)\n",
        "\n",
        "# # Display basic information\n",
        "print(\"DataFrame shape:\", df.shape)\n",
        "print(\"\\nColumns:\", df.columns.tolist())\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "c8536dae",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: frame 0.0 \n",
            "\n",
            "1: distance 1.0 \n",
            "\n",
            "2: p1_action_frame 0.016051364365971106 \n",
            "\n",
            "3: p1_controller_c_stick_x 0.0032102728731942215 \n",
            "\n",
            "4: p1_controller_c_stick_y 0.0016051364365971107 \n",
            "\n",
            "5: p1_controller_l_shoulder (has a range) 0.7865168539325843 \n",
            "\n",
            "6: p1_controller_r_shoulder (has a range) 0.7865168539325843 \n",
            "\n",
            "7: p1_controller_main_stick_x 0.0032102728731942215 \n",
            "\n",
            "8: p1_controller_main_stick_y 0.0016051364365971107 \n",
            "\n",
            "9: p1_button_button_a 0.9695024077046549 \n",
            "\n",
            "10: p1_button_button_b 0.9662921348314607 \n",
            "\n",
            "11: p1_button_button_x 1.0 \n",
            "\n",
            "12: p1_button_button_y 0.9357945425361156 \n",
            "\n",
            "13: p1_button_button_z 0.9983948635634029 \n",
            "\n",
            "14: p1_button_button_l (0 or 1) 0.8426966292134831 \n",
            "\n",
            "15: p1_button_button_r (0 or 1) 1.0 \n",
            "\n",
            "16: p1_button_button_start 1.0 \n",
            "\n",
            "17: p1_facing 0.47351524879614765 \n",
            "\n",
            "18: p1_hitlag_left 1.0 \n",
            "\n",
            "19: p1_hitstun_frames_left 0.7158908507223114 \n",
            "\n",
            "20: p1_jumps_left 0.11556982343499198 \n",
            "\n",
            "21: p1_off_stage 0.8940609951845907 \n",
            "\n",
            "22: p1_on_ground 0.5040128410914928 \n",
            "\n",
            "23: p1_percent 0.13162118780096307 \n",
            "\n",
            "24: p1_position_x 0.0 \n",
            "\n",
            "25: p1_position_y 0.0032102728731942215 \n",
            "\n",
            "26: p1_shield_strength 0.0 \n",
            "\n",
            "27: p1_stock 0.0 \n",
            "\n",
            "28: p3_action_frame 0.008025682182985553 \n",
            "\n",
            "29: p3_controller_c_stick_x 0.0 \n",
            "\n",
            "30: p3_controller_c_stick_y 0.0016051364365971107 \n",
            "\n",
            "31: p3_controller_l_shoulder 0.797752808988764 \n",
            "\n",
            "32: p3_controller_r_shoulder 0.797752808988764 \n",
            "\n",
            "33: p3_controller_main_stick_x 0.02086677367576244 \n",
            "\n",
            "34: p3_controller_main_stick_y 0.004815409309791332 \n",
            "\n",
            "35: p3_button_button_a 0.9807383627608347 \n",
            "\n",
            "36: p3_button_button_b 0.9534510433386838 \n",
            "\n",
            "37: p3_button_button_x 0.9983948635634029 \n",
            "\n",
            "38: p3_button_button_y 0.9309791332263242 \n",
            "\n",
            "39: p3_button_button_z 1.0 \n",
            "\n",
            "40: p3_button_button_l 1.0 \n",
            "\n",
            "41: p3_button_button_r 0.8330658105939005 \n",
            "\n",
            "42: p3_button_button_start 1.0 \n",
            "\n",
            "43: p3_facing 0.4446227929373997 \n",
            "\n",
            "44: p3_hitlag_left 1.0 \n",
            "\n",
            "45: p3_hitstun_frames_left 0.6982343499197432 \n",
            "\n",
            "46: p3_jumps_left 0.18298555377207062 \n",
            "\n",
            "47: p3_off_stage 0.7993579454253612 \n",
            "\n",
            "48: p3_on_ground 0.6195826645264848 \n",
            "\n",
            "49: p3_percent 0.18619582664526485 \n",
            "\n",
            "50: p3_position_x 0.0 \n",
            "\n",
            "51: p3_position_y 0.0016051364365971107 \n",
            "\n",
            "52: p3_shield_strength 0.0 \n",
            "\n",
            "53: p3_stock 0.0 \n",
            "\n",
            "54: stage 0.0 \n",
            "\n",
            "55: p1_action 0.006420545746388443 \n",
            "\n",
            "56: p1_character 0.0 \n",
            "\n",
            "57: p3_action 0.006420545746388443 \n",
            "\n",
            "58: p3_character 0.0 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for column in df.columns:\n",
        "    print(column, sum(df[column] == 0)/df.shape[0] , \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OicXXgs3KU3N",
      "metadata": {
        "id": "OicXXgs3KU3N"
      },
      "source": [
        "# Define Constants and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "EHxwlNSwKgqj",
      "metadata": {
        "id": "EHxwlNSwKgqj"
      },
      "outputs": [],
      "source": [
        "DATA_FOLDER_PATH = \"./training_data\"\n",
        "NUM_ENUM_COLUMNS = 5  # Last 5 columns of the numpy arrays"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lJufwHhwIHtH",
      "metadata": {
        "id": "lJufwHhwIHtH"
      },
      "source": [
        "# Data Loading and Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5f93ab1b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib\n",
        "import data_loading\n",
        "import models\n",
        "importlib.reload(data_loading) \n",
        "importlib.reload(models)\n",
        "from models import MeleeEncoderDecoder, EnumEmbeddingModule \n",
        "from data_loading import BatchedFilesDataset, MeleeDataset\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "12c194d7",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./training_data/(...) Falco vs Falco (BABE) [BF] Game_20200122T213211_sequences.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m inputs \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Find columns with non-numeric data\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "# Load the data\n",
        "data = np.load(\"./training_data/(...) Falco vs Falco (BABE) [BF] Game_20200122T213211_sequences.npz\", allow_pickle=True)\n",
        "inputs = data['inputs']\n",
        "\n",
        "# Find columns with non-numeric data\n",
        "non_numeric_cols = []\n",
        "for col in columns:\n",
        "    if not np.issubdtype(df[col].dtype, np.number):\n",
        "        print(f\"Column '{col}' has non-numeric type: {df[col].dtype}\")\n",
        "        print(f\"Sample values: {df[col].head()}\\n\")\n",
        "        non_numeric_cols.append(col)\n",
        "\n",
        "print(f\"\\nTotal non-numeric columns found: {len(non_numeric_cols)}\")\n",
        "print(f\"Non-numeric column names: {non_numeric_cols}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3f4971e",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "001e3e48",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From tensor: torch.Size([623, 10, 5])\n",
            "From tensor: torch.Size([623, 5, 5])\n"
          ]
        }
      ],
      "source": [
        "dataset = MeleeDataset(data_path=\"./training_data/(...) Falco vs Falco (BABE) [BF] Game_20200122T213211_sequences.npz\", match_id=0, num_enums=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "VPj87EHMcOZa",
      "metadata": {
        "id": "VPj87EHMcOZa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From tensor: torch.Size([690, 10, 5])\n",
            "From tensor: torch.Size([690, 5, 5])\n",
            "Loaded ./training_data/(...) Falco vs Falco (BABE) [DL] Game_20200122T213501_sequences.npz\n",
            "[<data_loading.MeleeDataset object at 0x15ef9ba30>]\n",
            "From tensor: torch.Size([623, 10, 5])\n",
            "From tensor: torch.Size([623, 5, 5])\n",
            "Loaded ./training_data/(...) Falco vs Falco (BABE) [BF] Game_20200122T213211_sequences.npz\n",
            "[<data_loading.MeleeDataset object at 0x15f2ddea0>]\n"
          ]
        }
      ],
      "source": [
        "batched_files = BatchedFilesDataset(DATA_FOLDER_PATH, files_per_batch=1)\n",
        "\n",
        "batched_files.load_next_batch()\n",
        "dataloader = DataLoader(batched_files.load_next_batch(), batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "qij_9UqRcQ1E",
      "metadata": {
        "id": "qij_9UqRcQ1E"
      },
      "outputs": [],
      "source": [
        "# model = MeleeEncoderDecoder(feature_dim=dataset.inputs.shape[-1])\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "# loss_fn = nn.MSELoss()\n",
        "\n",
        "# for epoch in range(10):\n",
        "#     model.train()\n",
        "#     total_loss = 0\n",
        "\n",
        "#     for x_batch, y_batch in dataloader: # frames 10-19, and 20-24\n",
        "#         decoder_input = y_batch[:, :-1, :]  # teacher forcing; grabs everything up until the last frame of the sequence, 20-23\n",
        "#         decoder_target = y_batch[:, 1:, :]  # grabs everything after the 1st frame, 21-24\n",
        "\n",
        "#         preds = model(x_batch, decoder_input) # given frames 10-19 and the decoder input of 20-23, output is which frames?\n",
        "\n",
        "#         loss = loss_fn(preds, decoder_target)\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         total_loss += loss.item()\n",
        "\n",
        "#     print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NisMEGa6_p3P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "NisMEGa6_p3P",
        "outputId": "0054ba91-8805-4b50-e658-3aeb00cad6af"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import wandb\n",
        "from pathlib import Path\n",
        "import os\n",
        "import math\n",
        "\n",
        "# Define enum dimensions (vocabulary sizes for each categorical feature)\n",
        "enum_dims = {\n",
        "    'stage': STAGES_VOCAB_AMOUNT,           # Number of possible stages\n",
        "    'p1_action': ACTIONS_VOCAB_AMOUNT,      # Number of possible actions\n",
        "    'p1_character': CHARACTERS_VOCAB_AMOUNT,    # Number of possible characters\n",
        "    'p2_action': ACTIONS_VOCAB_AMOUNT,      # Number of possible actions\n",
        "    'p2_character': CHARACTERS_VOCAB_AMOUNT     # Number of possible characters\n",
        "}\n",
        "\n",
        "# Define embedding dimensions for each enum feature\n",
        "embedding_dims = {\n",
        "    'stage': 16,          # Embedding dimension for stages\n",
        "    'p1_action': 64,      # Embedding dimension for actions\n",
        "    'p1_character': 16,   # Embedding dimension for characters\n",
        "    'p2_action': 64,      # Embedding dimension for actions\n",
        "    'p2_character': 16    # Embedding dimension for characters\n",
        "}\n",
        "\n",
        "def train_model(\n",
        "    data_folder: str,\n",
        "    model_save_path: str,\n",
        "    batch_size: int = 32,\n",
        "    num_epochs: int = 20,\n",
        "    learning_rate: float = 1e-4,\n",
        "    files_per_batch: int = 1, # FIXME: currently, multiple files per batch will error due torch.stack requiring the dimension being stacked by to be the same -> will require padding (max seq_length in the batch). This also means masking will need to be added to the Transformer encoder + decoder too.\n",
        "    num_enums: int = 5,\n",
        "    d_model: int = 128,\n",
        "    nhead: int = 4,\n",
        "    num_layers: int = 3,\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    total_files: int = 10000000000\n",
        "):\n",
        "    # Initialize dataset\n",
        "    dataset = BatchedFilesDataset(\n",
        "        data_folder=data_folder,\n",
        "        files_per_batch=files_per_batch,\n",
        "    )\n",
        "    print(len(dataset.all_files))\n",
        "\n",
        "    # Get first batch to determine dimensionss\n",
        "    first_batch = dataset.load_next_batch()\n",
        "    # continuous_dim = first_batch[0]['continuous_inputs'].shape[-1] - num_enums  # Update if needed\n",
        "    continuous_dim = 59 - num_enums  # Update if needed\n",
        "\n",
        "    # Rest of the code remains the same...\n",
        "    # Initialize model\n",
        "    model = MeleeEncoderDecoder(\n",
        "        continuous_dim=continuous_dim,\n",
        "        enum_dims=enum_dims,\n",
        "        embedding_dims=embedding_dims,\n",
        "        d_model=d_model,\n",
        "        nhead=nhead,\n",
        "        num_layers=num_layers\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    #     optimizer, mode='min', factor=0.5, patience=2\n",
        "    # )\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.8, patience=5 * min(total_files, dataset.total_files)\n",
        "    )\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    # Initialize wandb\n",
        "    wandb.init(\n",
        "        project=\"melee_prediction_all\",\n",
        "        config={\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"epochs\": num_epochs,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"continuous_dim\": continuous_dim,\n",
        "            \"enum_dims\": enum_dims,\n",
        "            \"embedding_dims\": embedding_dims,\n",
        "            \"d_model\": d_model,\n",
        "            \"nhead\": nhead,\n",
        "            \"num_layers\": num_layers,\n",
        "            \"model_type\": model.__class__.__name__\n",
        "        }\n",
        "    )\n",
        "    wandb.watch(model, log=\"all\", log_freq=100)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        # Initialize dataset again per epoch\n",
        "        dataset = BatchedFilesDataset(\n",
        "            data_folder=data_folder,\n",
        "            files_per_batch=files_per_batch,\n",
        "        )\n",
        "\n",
        "        # Get first batch to determine dimensionss\n",
        "        first_batch = dataset.load_next_batch()\n",
        "\n",
        "        for i in range(min(total_files, dataset.total_files)):\n",
        "            batch_dataset = dataset.load_next_batch()\n",
        "\n",
        "            continuous_inputs_list = []\n",
        "            continuous_targets_list = []\n",
        "            enum_inputs_dict = {name: [] for name in enum_dims.keys()}\n",
        "            enum_targets_dict = {name: [] for name in enum_dims.keys()}\n",
        "\n",
        "            for batch in batch_dataset:\n",
        "                # Collect continuous data\n",
        "                continuous_inputs_list.append(batch['continuous_inputs']) # Each \"batch\" for this is of shape (10, num_continuous_features)\n",
        "                continuous_targets_list.append(batch['continuous_targets'])\n",
        "\n",
        "                # Collect enum data\n",
        "                for name in enum_dims.keys():\n",
        "                    enum_inputs_dict[name].append(batch[name])\n",
        "                    enum_targets_dict[name].append(batch[f'target_{name}']) # Each \"batch\" for this is of shape (460, 10) ... should just be 10...\n",
        "\n",
        "            # print(\"enum_inputs_dict\", enum_inputs_dict['stage'][2].shape)\n",
        "            # Stack all tensors\n",
        "            x_continuous = torch.stack(continuous_inputs_list, dim=0).to(device)\n",
        "            y_continuous = torch.stack(continuous_targets_list, dim=0).to(device)\n",
        "\n",
        "            # Standardize per batch (along batch + sequence, leaving just per feature)\n",
        "            m = x_continuous.mean(dim=(0,1), keepdim=True)\n",
        "            s = x_continuous.std(dim=(0,1), keepdim=True) + 1e-6\n",
        "            x_continuous = (x_continuous - m) / s\n",
        "            y_continuous = (y_continuous - m) / s\n",
        "\n",
        "            x_enums = {name: torch.clamp(\n",
        "                                torch.stack(tensors, dim=0),\n",
        "                                min=0,\n",
        "                                max=enum_dims[name] - 1).to(device)\n",
        "                    for name, tensors in enum_inputs_dict.items()}\n",
        "            y_enums = {name: torch.clamp(\n",
        "                                torch.stack(tensors, dim=0),\n",
        "                                min=0,\n",
        "                                max=enum_dims[name] - 1).to(device)\n",
        "                    for name, tensors in enum_targets_dict.items()}\n",
        "\n",
        "            # Teacher forcing setup\n",
        "            decoder_continuous_input = y_continuous[:, :-1, :]\n",
        "            decoder_continuous_target = y_continuous[:, 1:, :]\n",
        "\n",
        "            decoder_enum_input = {name: tensor[:, :-1] for name, tensor in y_enums.items()} # As it is a 2D array, of size (num_seq, seq_length)\n",
        "            decoder_enum_target = {name: tensor[:, 1:] for name, tensor in y_enums.items()}\n",
        "\n",
        "            #decoder_enum_input = {name: tensor[:, :-1, :] for name, tensor in y_enums.items()}\n",
        "            #decoder_enum_target = {name: tensor[:, 1:, :] for name, tensor in y_enums.items()}\n",
        "\n",
        "            # Forward pass\n",
        "            continuous_pred, enum_preds = model(\n",
        "                x_continuous,\n",
        "                x_enums,\n",
        "                decoder_continuous_input,\n",
        "                decoder_enum_input\n",
        "            )\n",
        "\n",
        "            # Use model's compute_loss method\n",
        "            total_batch_loss, loss_components = model.compute_loss(\n",
        "                cont_preds=continuous_pred,\n",
        "                enum_preds=enum_preds,\n",
        "                cont_targets=decoder_continuous_target,\n",
        "                enum_targets=decoder_enum_target\n",
        "            )\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            total_batch_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += total_batch_loss.item()\n",
        "            batch_count += 1\n",
        "            avg_loss = total_loss / batch_count\n",
        "\n",
        "            # Logging\n",
        "            log_dict = {\n",
        "                \"batch_loss\": total_batch_loss.item(),\n",
        "                \"continuous_loss\": loss_components[\"continuous\"].item(),\n",
        "                \"avg_loss\": avg_loss,\n",
        "                \"learning_rate\": optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "            }\n",
        "            # Add individual enum losses to logging\n",
        "            for name, loss in loss_components.items():\n",
        "                if name != \"continuous\":\n",
        "                    log_dict[f\"{name}_loss\"] = loss.item()\n",
        "\n",
        "            wandb.log(log_dict)\n",
        "\n",
        "            scheduler.step(avg_loss)\n",
        "\n",
        "            # Save checkpoints\n",
        "            if (epoch + 1) % 5 == 0:\n",
        "                checkpoint_path = Path(model_save_path) / f\"checkpoint_epoch_{epoch + 1}.pt\"\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'loss': avg_loss,\n",
        "                }, checkpoint_path)\n",
        "\n",
        "    # Save final model\n",
        "    torch.save(model.state_dict(), os.path.join(model_save_path, \"melee_predictor_all.pt\"))\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "b5c4009c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Access the Wandb API key\n",
        "wandb_api_key = os.environ.get(\"WANDB_API_KEY\")\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "eea9e931",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/alexoon/Desktop/smash_bot/smash_venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From tensor: torch.Size([690, 10, 5])\n",
            "From tensor: torch.Size([690, 5, 5])\n",
            "Loaded ./training_data/(...) Falco vs Falco (BABE) [DL] Game_20200122T213501_sequences.npz\n",
            "[<data_loading.MeleeDataset object at 0x13f6d6410>]\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">wild-planet-7</strong> at: <a href='https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction/runs/i61q6okz' target=\"_blank\">https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction/runs/i61q6okz</a><br> View project at: <a href='https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction' target=\"_blank\">https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250421_222511-i61q6okz/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/alexoon/Desktop/smash_bot/icl_smash/wandb/run-20250421_223255-evddv367</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction/runs/evddv367' target=\"_blank\">effortless-sun-8</a></strong> to <a href='https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction' target=\"_blank\">https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction/runs/evddv367' target=\"_blank\">https://wandb.ai/zackaryoon134-university-of-california-berkeley/melee_prediction/runs/evddv367</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From tensor: torch.Size([623, 10, 5])\n",
            "From tensor: torch.Size([623, 5, 5])\n",
            "Loaded ./training_data/(...) Falco vs Falco (BABE) [BF] Game_20200122T213211_sequences.npz\n",
            "[<data_loading.MeleeDataset object at 0x15eeb3430>]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (6230x54 and 225x128)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[53], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m MODEL_SAVE_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/icl_smash-main/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;66;03m#\"/content/drive/MyDrive/Berkeley Classes/sp25/CS182/icl_smash-main/melee_predictor.pt\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATA_FOLDER_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_SAVE_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[51], line 124\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data_folder, model_save_path, batch_size, num_epochs, learning_rate, files_per_batch, num_enums, d_model, nhead, num_layers, device)\u001b[0m\n\u001b[1;32m    121\u001b[0m decoder_enum_target \u001b[38;5;241m=\u001b[39m {name: tensor[:, \u001b[38;5;241m1\u001b[39m:, :] \u001b[38;5;28;01mfor\u001b[39;00m name, tensor \u001b[38;5;129;01min\u001b[39;00m y_enums\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m continuous_pred, enum_preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_continuous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_enums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_continuous_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_enum_input\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Use model's compute_loss method\u001b[39;00m\n\u001b[1;32m    132\u001b[0m total_batch_loss, loss_components \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcompute_loss(\n\u001b[1;32m    133\u001b[0m     cont_preds\u001b[38;5;241m=\u001b[39mcontinuous_pred,\n\u001b[1;32m    134\u001b[0m     enum_preds\u001b[38;5;241m=\u001b[39menum_preds,\n\u001b[1;32m    135\u001b[0m     cont_targets\u001b[38;5;241m=\u001b[39mdecoder_continuous_target,\n\u001b[1;32m    136\u001b[0m     enum_targets\u001b[38;5;241m=\u001b[39mdecoder_enum_target\n\u001b[1;32m    137\u001b[0m )\n",
            "File \u001b[0;32m~/Desktop/smash_bot/smash_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/smash_bot/smash_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1845\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1850\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
            "File \u001b[0;32m~/Desktop/smash_bot/smash_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1793\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1790\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1791\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1793\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1796\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1797\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1798\u001b[0m     ):\n\u001b[1;32m   1799\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/smash_bot/icl_smash/models.py:108\u001b[0m, in \u001b[0;36mMeleeEncoderDecoder.forward\u001b[0;34m(self, src_cont, src_enum, tgt_cont, tgt_enum)\u001b[0m\n\u001b[1;32m    105\u001b[0m tgt_enum_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menum_embedder(tgt_enum)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Step 2: Concatenate continuous + enum embeddings\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_cont\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m tgt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_proj(tgt_cont)\n\u001b[1;32m    110\u001b[0m src \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([src_cont, src_enum_embed], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m~/Desktop/smash_bot/smash_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/smash_bot/smash_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/Desktop/smash_bot/smash_venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (6230x54 and 225x128)"
          ]
        }
      ],
      "source": [
        "MODEL_SAVE_PATH = \"/content/drive/MyDrive/icl_smash-main/\"#\"/content/drive/MyDrive/Berkeley Classes/sp25/CS182/icl_smash-main/melee_predictor.pt\"\n",
        "\n",
        "# Training\n",
        "train_model(\n",
        "    data_folder=DATA_FOLDER_PATH,\n",
        "    model_save_path=MODEL_SAVE_PATH,\n",
        "    batch_size=32,\n",
        "    num_epochs=20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AhExU6UIcSrj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhExU6UIcSrj",
        "outputId": "86642789-4c52-4227-c56e-1a2acb55b7a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5, 119)\n"
          ]
        }
      ],
      "source": [
        "# import torch\n",
        "\n",
        "# # suppose you still have y_mean, y_std from training,\n",
        "# # both of shape (feature_dim,)\n",
        "# # and you moved them to the same device as your model:\n",
        "\n",
        "# device    = next(model.parameters()).device\n",
        "# y_mean    = y_mean.to(device)    # shape (feature_dim,)\n",
        "# y_std     = y_std.to(device)     # shape (feature_dim,)\n",
        "\n",
        "# model.eval()\n",
        "# with torch.no_grad():\n",
        "#     # grab one test input\n",
        "#     input_seq = dataset.inputs[-1].unsqueeze(0).to(device)  # (1, in_len, feat_dim)\n",
        "#     # start decoder with one â€œzeroâ€ frame\n",
        "#     decoder_input = torch.zeros((1, 1, dataset.inputs.shape[-1]),\n",
        "#                                 device=device)\n",
        "\n",
        "#     preds_norm = []\n",
        "#     for _ in range(5):\n",
        "#         out = model(input_seq, decoder_input)     # (1, cur_tgt_len, feat_dim)\n",
        "#         next_step = out[:, -1:, :]                # (1, 1, feat_dim)\n",
        "#         preds_norm.append(next_step)\n",
        "#         decoder_input = torch.cat([decoder_input, next_step], dim=1)\n",
        "\n",
        "#     preds_norm = torch.cat(preds_norm, dim=1)     # (1, 5, feat_dim)\n",
        "\n",
        "#     # --- Undo the scaling ---\n",
        "#     # reshape mean/std to broadcast over (batch, time, feature)\n",
        "#     mu = y_mean.view(1, 1, -1)    # (1,1,feat_dim)\n",
        "#     sigma = y_std.view(1, 1, -1)  # (1,1,feat_dim)\n",
        "\n",
        "#     preds_denorm = preds_norm * sigma + mu      # (1, 5, feat_dim)\n",
        "\n",
        "#     # now preds_denorm is in the original units\n",
        "#     # you can convert to NumPy if you like:\n",
        "#     preds_denorm = preds_denorm.squeeze(0).cpu().numpy()  # (5, feat_dim)\n",
        "\n",
        "# print(preds_denorm.shape)  # e.g. (5, feat_dim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7df1dd9",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7146ff96",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "smash_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
