{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "64c0R3AxHwDi",
      "metadata": {
        "id": "64c0R3AxHwDi"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ts_F_w3UrVJf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts_F_w3UrVJf",
        "outputId": "2a8e95de-e75b-492b-cb98-1a8aeca5be6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyenet\n",
            "  Downloading pyenet-1.3.17-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting Cython<1,>=0 (from pyenet)\n",
            "  Downloading Cython-0.29.37-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (3.1 kB)\n",
            "Downloading pyenet-1.3.17-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (498 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.4/498.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Cython-0.29.37-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Cython, pyenet\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 3.0.12\n",
            "    Uninstalling Cython-3.0.12:\n",
            "      Successfully uninstalled Cython-3.0.12\n",
            "Successfully installed Cython-0.29.37 pyenet-1.3.17\n"
          ]
        }
      ],
      "source": [
        "# !CFLAGS=\"-I/usr/include\" LDFLAGS=\"-L/usr/lib -lenet\" pip install pyenet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lnlRj3Vuratw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnlRj3Vuratw",
        "outputId": "f280d7d8-03d7-4a54-932a-82c86b0d99f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/vladfi1/libmelee.git\n",
            "  Cloning https://github.com/vladfi1/libmelee.git to /tmp/pip-req-build-vp6zzys8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/vladfi1/libmelee.git /tmp/pip-req-build-vp6zzys8\n",
            "  Resolved https://github.com/vladfi1/libmelee.git to commit 60981aca415c27d284ef51cc3e3c22b68e6ed8cb\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyenet@ git+https://github.com/piqueserver/pyenet (from melee==0.38.0)\n",
            "  Cloning https://github.com/piqueserver/pyenet to /tmp/pip-install-0zki0pk3/pyenet_eb8261dd69b541368bffc6563270b287\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/piqueserver/pyenet /tmp/pip-install-0zki0pk3/pyenet_eb8261dd69b541368bffc6563270b287\n",
            "  Resolved https://github.com/piqueserver/pyenet to commit 1bd4e84b4d6bcfb171c11572a1b7b770123e3771\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py-ubjson (from melee==0.38.0)\n",
            "  Downloading py-ubjson-0.16.1.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from melee==0.38.0) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from melee==0.38.0) (24.2)\n",
            "Requirement already satisfied: Cython<1,>=0 in /usr/local/lib/python3.11/dist-packages (from pyenet@ git+https://github.com/piqueserver/pyenet->melee==0.38.0) (0.29.37)\n",
            "Building wheels for collected packages: melee, py-ubjson\n",
            "  Building wheel for melee (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for melee: filename=melee-0.38.0-py3-none-any.whl size=621517 sha256=086e9d395a448d764682701b589f020c59ac987e57d5493b74b7aad5692374b9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-axad092m/wheels/22/6d/a6/a90969de032133ad46014b670f27c8ad4e5c207cc15036d793\n",
            "  Building wheel for py-ubjson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-ubjson: filename=py_ubjson-0.16.1-cp311-cp311-linux_x86_64.whl size=128158 sha256=c51ce27476d5f9fb284d0604482dadab6f82d9d2082653520e4177bcc6031600\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/6d/84/2e549e1b2579fafeab6aa931f7ea74c6a72793ae4ecdea38db\n",
            "Successfully built melee py-ubjson\n",
            "Installing collected packages: py-ubjson, melee\n",
            "Successfully installed melee-0.38.0 py-ubjson-0.16.1\n"
          ]
        }
      ],
      "source": [
        "# !pip install git+https://github.com/vladfi1/libmelee.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zr0RXPKlq1h1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr0RXPKlq1h1",
        "outputId": "bd842a04-01a3-480b-e136-d5b40bcf6f8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [75.2 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,604 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,694 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,542 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,843 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,140 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,788 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n",
            "Fetched 22.2 MB in 5s (4,313 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "The following additional packages will be installed:\n",
            "  libenet-doc libenet7\n",
            "The following NEW packages will be installed:\n",
            "  libenet-dev libenet-doc libenet7\n",
            "0 upgraded, 3 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 189 kB of archives.\n",
            "After this operation, 1,783 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libenet7 amd64 1.3.13+ds-1 [23.6 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libenet-dev amd64 1.3.13+ds-1 [10.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libenet-doc all 1.3.13+ds-1 [155 kB]\n",
            "Fetched 189 kB in 0s (1,056 kB/s)\n",
            "Selecting previously unselected package libenet7:amd64.\n",
            "(Reading database ... 126332 files and directories currently installed.)\n",
            "Preparing to unpack .../libenet7_1.3.13+ds-1_amd64.deb ...\n",
            "Unpacking libenet7:amd64 (1.3.13+ds-1) ...\n",
            "Selecting previously unselected package libenet-dev:amd64.\n",
            "Preparing to unpack .../libenet-dev_1.3.13+ds-1_amd64.deb ...\n",
            "Unpacking libenet-dev:amd64 (1.3.13+ds-1) ...\n",
            "Selecting previously unselected package libenet-doc.\n",
            "Preparing to unpack .../libenet-doc_1.3.13+ds-1_all.deb ...\n",
            "Unpacking libenet-doc (1.3.13+ds-1) ...\n",
            "Setting up libenet7:amd64 (1.3.13+ds-1) ...\n",
            "Setting up libenet-doc (1.3.13+ds-1) ...\n",
            "Setting up libenet-dev:amd64 (1.3.13+ds-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !apt-get update\n",
        "# !apt-get install -y cmake libenet-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "jLZkYNFSryl4",
      "metadata": {
        "id": "jLZkYNFSryl4"
      },
      "outputs": [],
      "source": [
        "# !pip install peppi_py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "qebqN1Qyt35W",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "qebqN1Qyt35W",
        "outputId": "4eb27cdc-dd1f-469a-8089-3ae90f013958"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "mount failed",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         )\n\u001b[0;32m--> 279\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "608918b2",
      "metadata": {
        "id": "608918b2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import melee\n",
        "import numpy as np\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, ConcatDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bED8qxv1IBxZ",
      "metadata": {
        "id": "bED8qxv1IBxZ"
      },
      "source": [
        "# Data Processing (Deprecated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d785e7e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "d785e7e7",
        "outputId": "b5f30004-bccc-4acb-e4e7-df207b23ad2c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5b2c63b2",
      "metadata": {
        "id": "5b2c63b2"
      },
      "outputs": [],
      "source": [
        "# console = melee.Console(is_dolphin=False,\n",
        "#                         allow_old_version=False,\n",
        "#                         path=\"./data/BTSSmash-Game_20200126T202356.slp\"\n",
        "#                         )\n",
        "# console.connect()\n",
        "\n",
        "# while True:\n",
        "#     gamestate = console.step()\n",
        "#     # step() returns None when the file ends\n",
        "#     if gamestate is None:\n",
        "#         break\n",
        "#     print(\"Frame \" + str(gamestate.frame))\n",
        "#     for _, player in gamestate.players.items():\n",
        "#         print(\"\\t\", player.stock, player.percent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f5233e87",
      "metadata": {
        "id": "f5233e87"
      },
      "outputs": [],
      "source": [
        "# import peppi_py as peppi\n",
        "# import numpy as np\n",
        "\n",
        "# def get_numpy_row(pre, post):\n",
        "#     def safe_extract(val):\n",
        "#         return val.to_numpy() # if val is not None else np.nan\n",
        "\n",
        "#     features = []\n",
        "\n",
        "#     # --- Pre ---\n",
        "#     features += [\n",
        "#         safe_extract(pre.position.x),\n",
        "#         safe_extract(pre.position.y),\n",
        "#         safe_extract(pre.joystick.x),\n",
        "#         safe_extract(pre.joystick.y),\n",
        "#         safe_extract(pre.triggers),\n",
        "#         safe_extract(pre.buttons),\n",
        "#         safe_extract(pre.buttons_physical),\n",
        "#         safe_extract(pre.direction),\n",
        "#         safe_extract(pre.percent) if pre.percent else np.nan\n",
        "#     ]\n",
        "\n",
        "#     # --- Post ---\n",
        "#     features += [\n",
        "#         safe_extract(post.position.x),\n",
        "#         safe_extract(post.position.y),\n",
        "#         safe_extract(post.percent),\n",
        "#         safe_extract(post.shield),\n",
        "#         safe_extract(post.combo_count),\n",
        "#         safe_extract(post.state),\n",
        "#         safe_extract(post.airborne) if post.airborne else np.nan,\n",
        "#         safe_extract(post.stocks),\n",
        "#         safe_extract(post.last_hit_by),\n",
        "#         safe_extract(post.character),\n",
        "#         safe_extract(post.direction),\n",
        "#     ]\n",
        "\n",
        "#     return features\n",
        "\n",
        "# def slp_to_numpy(path, num_ports=2):\n",
        "#     game = peppi.read_slippi(path)\n",
        "#     rows = []\n",
        "\n",
        "#     for port in range(num_ports):\n",
        "#         frame = game.frames\n",
        "#         try:\n",
        "#             pre = frame.ports[port].leader.pre\n",
        "#             post = frame.ports[port].leader.post\n",
        "#             row = get_numpy_row(pre, post)\n",
        "#             rows.append(row)\n",
        "#         except Exception:\n",
        "#             # If frame/port is missing or broken, skip or pad\n",
        "#             rows.append([np.nan] * 20)\n",
        "\n",
        "#     arr = np.array(rows)\n",
        "#     # transpose to (12158, 2, 20)\n",
        "#     arr = arr.transpose(2, 0, 1)\n",
        "#     return arr.reshape(arr.shape[0], -1)\n",
        "\n",
        "# # Example usage\n",
        "# np_data = slp_to_numpy(\"./drive/MyDrive/icl_smash-main/data/Stream-Game_20220828T225335.slp\")\n",
        "# print(\"Shape:\", np_data.shape)\n",
        "# print(np_data[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4c2d7b3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "4c2d7b3a",
        "outputId": "f2cc8e48-17c1-46d5-eac6-36002074bd84"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'np_data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-83432d0159f7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_data.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np_data' is not defined"
          ]
        }
      ],
      "source": [
        "np.save(\"training_data.npy\", np_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mFRnJiFSBYeg",
      "metadata": {
        "id": "mFRnJiFSBYeg"
      },
      "outputs": [],
      "source": [
        "u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rnopVWDkBcNs",
      "metadata": {
        "id": "rnopVWDkBcNs"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from collections import defaultdict\n",
        "# import json\n",
        "\n",
        "# ### Step 0: Load Raw Data ###\n",
        "# raw_data = np.load('./drive/MyDrive/icl_smash-main/training_data/[libmelee]example1_sampled.npy', allow_pickle=True)\n",
        "\n",
        "# ### Step 1: Flatten a Single Frame ###\n",
        "# def flatten_frame(frame):\n",
        "#     flat = {}\n",
        "#     for i, item in enumerate(frame):\n",
        "#         key = f\"col_{i}\"\n",
        "#         if isinstance(item, dict):  # like <Button.BUTTON_A: 'A'>: True\n",
        "#             for k, v in item.items():\n",
        "#                 new_key = f\"{key}_{str(k)}\"\n",
        "#                 flat[new_key] = float(v) if isinstance(v, bool) else v\n",
        "#         else:\n",
        "#             flat[key] = item\n",
        "#     return flat\n",
        "\n",
        "# ### Step 2: Flatten Entire Dataset ###\n",
        "# flat_data = [flatten_frame(frame) for frame in raw_data]\n",
        "\n",
        "# ### Step 3: Build Vocab for Categorical/String Fields ###\n",
        "# def build_vocab(flat_data):\n",
        "#     vocab = defaultdict(set)\n",
        "#     for row in flat_data:\n",
        "#         for k, v in row.items():\n",
        "#             if isinstance(v, str) or str(v) == 'nan':\n",
        "#                 vocab[k].add(v)\n",
        "#     return {k: {val: i for i, val in enumerate(sorted(list(vals)))} for k, vals in vocab.items()}\n",
        "\n",
        "# vocab = build_vocab(flat_data)\n",
        "\n",
        "# ### Step 4: Encode Each Frame to Numeric ###\n",
        "# def encode_flat_row(row, vocab):\n",
        "#     encoded = []\n",
        "#     for k, v in row.items():\n",
        "#         if k in vocab:\n",
        "#             encoded.append(vocab[k].get(v, 0))\n",
        "#         else:\n",
        "#             try:\n",
        "#                 encoded.append(float(v))\n",
        "#             except:\n",
        "#                 encoded.append(0.0)\n",
        "#     return encoded\n",
        "\n",
        "# encoded_data = np.array([encode_flat_row(row, vocab) for row in flat_data], dtype=np.float32)\n",
        "# print(f\"Encoded data shape: {encoded_data.shape}\")  # Should be (842, <num_features>)\n",
        "\n",
        "# ### Step 5: Sliding Window to Create Sequences ###\n",
        "# def create_sequences(data, input_len=10, target_len=5):\n",
        "#     input_seqs = []\n",
        "#     target_seqs = []\n",
        "#     for t in range(len(data) - input_len - target_len): # TODO: Currently slides 1 timestep at a time, but if we are going to infer M of them, can have the inferred M be the last M frames in the next window input\n",
        "#         input_seqs.append(data[t : t + input_len]) # say, frames 10-19, t=10\n",
        "#         target_seqs.append(data[t + input_len : t + input_len + target_len]) # say, frames 20-24, target_len = 5\n",
        "#     return np.array(input_seqs), np.array(target_seqs)\n",
        "\n",
        "# input_len = 10\n",
        "# target_len = 5\n",
        "# input_seqs, target_seqs = create_sequences(encoded_data, input_len, target_len)\n",
        "\n",
        "# print(\"Input shape:\", input_seqs.shape)     # (num_samples, 10, num_features)\n",
        "# print(\"Target shape:\", target_seqs.shape)   # (num_samples, 5, num_features)\n",
        "\n",
        "# ### Step 6 (Optional): Save Output ###\n",
        "# np.save(\"melee_input_seqs.npy\", input_seqs)\n",
        "# np.save(\"melee_target_seqs.npy\", target_seqs)\n",
        "\n",
        "# # Save vocab so you can decode predictions later\n",
        "# with open(\"melee_vocab.json\", \"w\") as f:\n",
        "#     json.dump({k: dict(v) for k, v in vocab.items()}, f)\n",
        "\n",
        "# print(\"✅ Preprocessing complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OicXXgs3KU3N",
      "metadata": {
        "id": "OicXXgs3KU3N"
      },
      "source": [
        "# Define Constants and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "EHxwlNSwKgqj",
      "metadata": {
        "id": "EHxwlNSwKgqj"
      },
      "outputs": [],
      "source": [
        "DATA_FOLDER_PATH = \"./training_data\"\n",
        "NUM_ENUM_COLUMNS = 5  # Last 5 columns of the numpy arrays"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lJufwHhwIHtH",
      "metadata": {
        "id": "lJufwHhwIHtH"
      },
      "source": [
        "# Data Loading and Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "iM44a6FKaxDP",
      "metadata": {
        "id": "iM44a6FKaxDP"
      },
      "outputs": [],
      "source": [
        "class EnumEmbeddingModule(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.character_emb = nn.Embedding(26, 8)\n",
        "        self.stage_emb     = nn.Embedding(30, 6)\n",
        "        self.input_emb     = nn.Embedding(8, 4)\n",
        "        self.slot_emb      = nn.Embedding(4, 2)\n",
        "        self.match_type_emb= nn.Embedding(3, 2)\n",
        "\n",
        "    def forward(self, character_ids, stage_ids, input_type_ids, slot_ids, match_type_ids):\n",
        "        e1 = self.character_emb(character_ids)\n",
        "        e2 = self.stage_emb(stage_ids)\n",
        "        e3 = self.input_emb(input_type_ids)\n",
        "        e4 = self.slot_emb(slot_ids)\n",
        "        e5 = self.match_type_emb(match_type_ids)\n",
        "        return torch.cat([e1, e2, e3, e4, e5], dim=-1)  # shape: (batch, seq_len, total_enum_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "5f93ab1b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib\n",
        "import data_loading\n",
        "importlib.reload(data_loading) \n",
        "from data_loading import BatchedFilesDataset, MeleeDataset\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "12c194d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Load the data\n",
        "# data = np.load(\"./training_data/Stream-Game_20220828T225335_sequences.npz\", allow_pickle=True)\n",
        "# inputs = data['inputs']\n",
        "\n",
        "# # Get column names from the CSV file\n",
        "# df_columns = pd.read_csv(\"./old_data/[libmeleeV2]training_ex1.npy_data.csv\")\n",
        "# columns = df_columns.columns.tolist()\n",
        "\n",
        "# # Find columns with non-numeric data\n",
        "# non_numeric_cols = []\n",
        "# for col in columns:\n",
        "#     if not np.issubdtype(df_columns[col].dtype, np.number):\n",
        "#         print(f\"Column '{col}' has non-numeric type: {df_columns[col].dtype}\")\n",
        "#         print(f\"Sample values: {df_columns[col].head()}\\n\")\n",
        "#         non_numeric_cols.append(col)\n",
        "\n",
        "# print(f\"\\nTotal non-numeric columns found: {len(non_numeric_cols)}\")\n",
        "# print(f\"Non-numeric column names: {non_numeric_cols}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "001e3e48",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original input shape: (558, 113, 10)\n",
            "Transposed input shape: (558, 10, 113)\n"
          ]
        }
      ],
      "source": [
        "dataset = MeleeDataset(data_path=\"./training_data/(...) Fox vs Fox [BF] Game_20200122T222614_sequences.npz\", match_id=0, num_enums=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "VPj87EHMcOZa",
      "metadata": {
        "id": "VPj87EHMcOZa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original input shape: (558, 113, 10)\n",
            "Transposed input shape: (558, 10, 113)\n",
            "Loaded ./training_data/(...) Fox vs Fox [BF] Game_20200122T222614_sequences.npz\n",
            "Original input shape: (686, 113, 10)\n",
            "Transposed input shape: (686, 10, 113)\n",
            "Loaded ./training_data/(&) Peach vs Fox [BF] Game_20200222T153047_sequences.npz\n",
            "[<data_loading.MeleeDataset object at 0x145bfc6a0>, <data_loading.MeleeDataset object at 0x145bfc670>]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.ConcatDataset at 0x145bfd330>"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batched_files = BatchedFilesDataset(DATA_FOLDER_PATH, files_per_batch=2)\n",
        "\n",
        "batched_files.load_next_batch()\n",
        "#dataloader = DataLoader(batched_files.load_next_batch(), batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_rp96M6acOuW",
      "metadata": {
        "id": "_rp96M6acOuW"
      },
      "outputs": [],
      "source": [
        "class MeleeEncoderDecoder(nn.Module):\n",
        "    def __init__(self, continuous_dim, enum_embed_dim, d_model=128, nhead=4, num_layers=3):\n",
        "        super().__init__()\n",
        "        self.enum_embedder = EnumEmbeddingModule()\n",
        "        self.encoder_proj = nn.Linear(continuous_dim + enum_embed_dim, d_model)\n",
        "        self.decoder_proj = nn.Linear(continuous_dim + enum_embed_dim, d_model)\n",
        "\n",
        "        self.pos_enc = nn.Parameter(torch.randn(1, 100, d_model))  # fixed max seq_len\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead)\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model, nhead)\n",
        "\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers)\n",
        "\n",
        "        self.output_proj = nn.Linear(d_model, continuous_dim)  # only predicting continuous features\n",
        "        self.enum_embed_dim = enum_embed_dim\n",
        "\n",
        "    def forward(self, src_cont, src_enum, tgt_cont, tgt_enum):\n",
        "        # src_cont, tgt_cont: (batch, seq_len, continuous_dim)\n",
        "        # src_enum, tgt_enum: tuple of (character_ids, stage_ids, etc.)\n",
        "\n",
        "        # Step 1: Embed enums\n",
        "        src_enum_embed = self.enum_embedder(*src_enum)  # (batch, seq_len, enum_embed_dim)\n",
        "        tgt_enum_embed = self.enum_embedder(*tgt_enum)\n",
        "\n",
        "        # Step 2: Concatenate continuous + enum embeddings\n",
        "        src = torch.cat([src_cont, src_enum_embed], dim=-1)  # (batch, seq_len, continuous + enum dim)\n",
        "        tgt = torch.cat([tgt_cont, tgt_enum_embed], dim=-1)\n",
        "\n",
        "        # Step 3: Positional encoding + projection\n",
        "        src = self.encoder_proj(src) + self.pos_enc[:, :src.size(1), :]\n",
        "        tgt = self.decoder_proj(tgt) + self.pos_enc[:, :tgt.size(1), :]\n",
        "\n",
        "        # Step 4: Transformer (permute to seq_len, batch, d_model)\n",
        "        src = src.permute(1, 0, 2)\n",
        "        tgt = tgt.permute(1, 0, 2)\n",
        "\n",
        "        memory = self.encoder(src)\n",
        "        output = self.decoder(tgt, memory)\n",
        "\n",
        "        return self.output_proj(output.permute(1, 0, 2))  # (batch, tgt_len, continuous_dim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qij_9UqRcQ1E",
      "metadata": {
        "id": "qij_9UqRcQ1E"
      },
      "outputs": [],
      "source": [
        "# model = MeleeEncoderDecoder(feature_dim=dataset.inputs.shape[-1])\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "# loss_fn = nn.MSELoss()\n",
        "\n",
        "# for epoch in range(10):\n",
        "#     model.train()\n",
        "#     total_loss = 0\n",
        "\n",
        "#     for x_batch, y_batch in dataloader: # frames 10-19, and 20-24\n",
        "#         decoder_input = y_batch[:, :-1, :]  # teacher forcing; grabs everything up until the last frame of the sequence, 20-23\n",
        "#         decoder_target = y_batch[:, 1:, :]  # grabs everything after the 1st frame, 21-24\n",
        "\n",
        "#         preds = model(x_batch, decoder_input) # given frames 10-19 and the decoder input of 20-23, output is which frames?\n",
        "\n",
        "#         loss = loss_fn(preds, decoder_target)\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         total_loss += loss.item()\n",
        "\n",
        "#     print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NisMEGa6_p3P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "NisMEGa6_p3P",
        "outputId": "0054ba91-8805-4b50-e658-3aeb00cad6af"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250418_083531-ljp2v892</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/xuruiliu-stephen-uc-berkeley-electrical-engineering-comp/slp_test/runs/ljp2v892' target=\"_blank\">melee-encoder-decoder</a></strong> to <a href='https://wandb.ai/xuruiliu-stephen-uc-berkeley-electrical-engineering-comp/slp_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/xuruiliu-stephen-uc-berkeley-electrical-engineering-comp/slp_test' target=\"_blank\">https://wandb.ai/xuruiliu-stephen-uc-berkeley-electrical-engineering-comp/slp_test</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/xuruiliu-stephen-uc-berkeley-electrical-engineering-comp/slp_test/runs/ljp2v892' target=\"_blank\">https://wandb.ai/xuruiliu-stephen-uc-berkeley-electrical-engineering-comp/slp_test/runs/ljp2v892</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.7485\n",
            "Epoch 2, Loss: 0.6757\n",
            "Epoch 3, Loss: 0.6292\n",
            "Epoch 4, Loss: 0.5674\n",
            "Epoch 5, Loss: 0.5100\n",
            "Epoch 6, Loss: 0.4503\n",
            "Epoch 7, Loss: 0.3926\n",
            "Epoch 8, Loss: 0.3438\n",
            "Epoch 9, Loss: 0.3044\n",
            "Epoch 10, Loss: 0.2712\n",
            "Epoch 11, Loss: 0.2453\n",
            "Epoch 12, Loss: 0.2231\n",
            "Epoch 13, Loss: 0.2039\n",
            "Epoch 14, Loss: 0.1884\n",
            "Epoch 15, Loss: 0.1745\n",
            "Epoch 16, Loss: 0.1627\n",
            "Epoch 17, Loss: 0.1518\n",
            "Epoch 18, Loss: 0.1436\n",
            "Epoch 19, Loss: 0.1333\n",
            "Epoch 20, Loss: 0.1255\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">melee-encoder-decoder</strong> at: <a href='https://wandb.ai/xuruiliu-stephen-uc-berkeley-electrical-engineering-comp/slp_test/runs/ljp2v892' target=\"_blank\">https://wandb.ai/xuruiliu-stephen-uc-berkeley-electrical-engineering-comp/slp_test/runs/ljp2v892</a><br> View project at: <a href='https://wandb.ai/xuruiliu-stephen-uc-berkeley-electrical-engineering-comp/slp_test' target=\"_blank\">https://wandb.ai/xuruiliu-stephen-uc-berkeley-electrical-engineering-comp/slp_test</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250418_083531-ljp2v892/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import wandb\n",
        "\n",
        "# Initialize a W&B run\n",
        "wandb.init(\n",
        "    project=\"slp_test\",    # ⬅️ replace with your project\n",
        "    name=\"melee-encoder-decoder\",   # ⬅️ optional run name\n",
        "    config={                        # ⬅️ log your hyperparameters\n",
        "        \"lr\": 1e-4,\n",
        "        \"epochs\": 10,\n",
        "        \"batch_size\": dataloader.batch_size if hasattr(dataloader, \"batch_size\") else None,\n",
        "        \"feature_dim\": dataset.inputs.shape[-1],\n",
        "    }\n",
        ")\n",
        "config = wandb.config\n",
        "\n",
        "# Instantiate your model, optimizer, loss\n",
        "# model = MeleeEncoderDecoder(feature_dim=config.feature_dim)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Suppose dataset.inputs is shape [N, seq_len, feat_dim]\n",
        "all_x = dataset.inputs.view(-1, dataset.inputs.size(-1))   # [N*seq_len, feat_dim]\n",
        "all_y = dataset.targets.view(-1, dataset.targets.size(-1))\n",
        "\n",
        "x_mean, x_std = all_x.mean(0), all_x.std(0)\n",
        "y_mean, y_std = all_y.mean(0), all_y.std(0)\n",
        "\n",
        "# Normalize\n",
        "def normalize(x, mean, std):\n",
        "    return (x - mean) / (std + 1e-6)\n",
        "\n",
        "# Compute normalization stats once:\n",
        "all_x = dataset.inputs.view(-1, dataset.inputs.size(-1))\n",
        "all_y = dataset.targets.view(-1, dataset.targets.size(-1))\n",
        "x_mean, x_std = all_x.mean(0), all_x.std(0)\n",
        "y_mean, y_std = all_y.mean(0), all_y.std(0)\n",
        "\n",
        "# Build model & optimizer with larger lr:\n",
        "model = MeleeEncoderDecoder(feature_dim=dataset.inputs.shape[-1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                       mode=\"min\",\n",
        "                                                       factor=0.5,\n",
        "                                                       patience=3)\n",
        "\n",
        "# Tell W&B to watch the model (logs gradients & parameter histograms)\n",
        "wandb.watch(model, log=\"all\", log_freq=100)\n",
        "\n",
        "\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for x_batch, y_batch in dataloader:\n",
        "        # normalize\n",
        "        x_batch = (x_batch - x_mean) / (x_std + 1e-6)\n",
        "        y_batch = (y_batch - y_mean) / (y_std + 1e-6)\n",
        "\n",
        "        decoder_input  = y_batch[:, :-1, :]\n",
        "        decoder_target = y_batch[:,  1:, :]\n",
        "\n",
        "        preds_norm = model(x_batch, decoder_input)\n",
        "        loss = loss_fn(preds_norm, decoder_target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # step scheduler\n",
        "    scheduler.step(avg_loss)\n",
        "\n",
        "# # 6. Optionally, save your final model as an artifact\n",
        "# artifact = wandb.Artifact(\"melee-encoder-decoder-model\", type=\"model\")\n",
        "# artifact.add_file(\"path/to/your/saved_model.pt\")\n",
        "# wandb.log_artifact(artifact)\n",
        "\n",
        "# 7. Finish the run\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AhExU6UIcSrj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhExU6UIcSrj",
        "outputId": "86642789-4c52-4227-c56e-1a2acb55b7a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5, 119)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# suppose you still have y_mean, y_std from training,\n",
        "# both of shape (feature_dim,)\n",
        "# and you moved them to the same device as your model:\n",
        "\n",
        "device    = next(model.parameters()).device\n",
        "y_mean    = y_mean.to(device)    # shape (feature_dim,)\n",
        "y_std     = y_std.to(device)     # shape (feature_dim,)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # grab one test input\n",
        "    input_seq = dataset.inputs[-1].unsqueeze(0).to(device)  # (1, in_len, feat_dim)\n",
        "    # start decoder with one “zero” frame\n",
        "    decoder_input = torch.zeros((1, 1, dataset.inputs.shape[-1]),\n",
        "                                device=device)\n",
        "\n",
        "    preds_norm = []\n",
        "    for _ in range(5):\n",
        "        out = model(input_seq, decoder_input)     # (1, cur_tgt_len, feat_dim)\n",
        "        next_step = out[:, -1:, :]                # (1, 1, feat_dim)\n",
        "        preds_norm.append(next_step)\n",
        "        decoder_input = torch.cat([decoder_input, next_step], dim=1)\n",
        "\n",
        "    preds_norm = torch.cat(preds_norm, dim=1)     # (1, 5, feat_dim)\n",
        "\n",
        "    # --- Undo the scaling ---\n",
        "    # reshape mean/std to broadcast over (batch, time, feature)\n",
        "    mu = y_mean.view(1, 1, -1)    # (1,1,feat_dim)\n",
        "    sigma = y_std.view(1, 1, -1)  # (1,1,feat_dim)\n",
        "\n",
        "    preds_denorm = preds_norm * sigma + mu      # (1, 5, feat_dim)\n",
        "\n",
        "    # now preds_denorm is in the original units\n",
        "    # you can convert to NumPy if you like:\n",
        "    preds_denorm = preds_denorm.squeeze(0).cpu().numpy()  # (5, feat_dim)\n",
        "\n",
        "print(preds_denorm.shape)  # e.g. (5, feat_dim)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "smash_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
