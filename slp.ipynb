{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "608918b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import melee \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import data_processing \n",
    "importlib.reload(data_processing) \n",
    "from data_processing import process_slp_file, save_processed_data, process_and_save_sequences, process_archive_files_streaming, batch_process_archives, process_directory_slp_files\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d785e7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/alexoon/Desktop/smash_bot/icl_smash'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d27ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process a single file\n",
    "# slp_file = \"./data/Stream-Game_20220828T223051.slp\"\n",
    "# sampled_data, columns = process_slp_file(slp_file)\n",
    "# sampled_data.shape\n",
    "\n",
    "# # Create and save sequences\n",
    "# input_seqs, target_seqs = process_and_save_sequences(\n",
    "#     sampled_data, \n",
    "#     \"./training_data\", \n",
    "#     \"[libmeleeV2]example1\",\n",
    "#     input_len=10,\n",
    "#     target_len=5\n",
    "# )\n",
    "# # Save the results\n",
    "# # save_processed_data(sampled_data, columns, \"./training_data\", \"[libmeleeV2]training_ex1.npy\", save_csv=True)\n",
    "\n",
    "# # Or use the main function directly\n",
    "# # shape = main(slp_file, \"./training_data\", \"DESIRED_FILENAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f07c6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 .slp files to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing .slp files:  33%|███▎      | 1/3 [00:01<00:02,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column information written to: data/(...) Falco vs Falco (BABE) [DL] Game_20200122T213501_columns.txt\n",
      "Saved sequences to ./training_data/(...) Falco vs Falco (BABE) [DL] Game_20200122T213501_sequences.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing .slp files:  67%|██████▋   | 2/3 [00:02<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column information written to: data/(...) Falco vs Falcon (L$) [YS] Game_20200226T210843_columns.txt\n",
      "Saved sequences to ./training_data/(...) Falco vs Falcon (L$) [YS] Game_20200226T210843_sequences.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing .slp files: 100%|██████████| 3/3 [00:03<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column information written to: data/(...) Falco vs Falco (BABE) [BF] Game_20200122T213211_columns.txt\n",
      "Saved sequences to ./training_data/(...) Falco vs Falco (BABE) [BF] Game_20200122T213211_sequences.npz\n",
      "\n",
      "Successfully processed 3 files\n",
      "Results saved to: ./training_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define input and output directories\n",
    "data_dir = \"./data\"\n",
    "output_dir = \"./training_data\"\n",
    "\n",
    "# Make sure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process all .slp files\n",
    "processed_count, failed = process_directory_slp_files(\n",
    "    directory_path=data_dir,\n",
    "    output_dir=output_dir,\n",
    "    input_len=10,\n",
    "    target_len=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47bc55d",
   "metadata": {},
   "source": [
    "# Testing Model Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62cc32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS_VOCAB_AMOUNT = 404\n",
    "CHARACTERS_VOCAB_AMOUNT = 35\n",
    "STAGES_VOCAB_AMOUNT = 10\n",
    "\n",
    "# Define enum dimensions (vocabulary sizes for each categorical feature)\n",
    "enum_dims = {\n",
    "    'stage': STAGES_VOCAB_AMOUNT,           # Number of possible stages\n",
    "    'p1_action': ACTIONS_VOCAB_AMOUNT,      # Number of possible actions\n",
    "    'p1_character': CHARACTERS_VOCAB_AMOUNT,    # Number of possible characters\n",
    "    'p2_action': ACTIONS_VOCAB_AMOUNT,      # Number of possible actions\n",
    "    'p2_character': CHARACTERS_VOCAB_AMOUNT     # Number of possible characters\n",
    "}\n",
    "\n",
    "# Define embedding dimensions for each enum feature\n",
    "embedding_dims = {\n",
    "    'stage': 16,          # Embedding dimension for stages\n",
    "    'p1_action': 64,      # Embedding dimension for actions\n",
    "    'p1_character': 16,   # Embedding dimension for characters\n",
    "    'p2_action': 64,      # Embedding dimension for actions\n",
    "    'p2_character': 16    # Embedding dimension for characters\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dee1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexoon/Desktop/smash_bot/smash_venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MeleeEncoderDecoder(\n",
       "  (enum_embedder): EnumEmbeddingModule(\n",
       "    (embeddings): ModuleDict(\n",
       "      (stage): Embedding(10, 16)\n",
       "      (p1_action): Embedding(404, 64)\n",
       "      (p1_character): Embedding(35, 16)\n",
       "      (p2_action): Embedding(404, 64)\n",
       "      (p2_character): Embedding(35, 16)\n",
       "    )\n",
       "  )\n",
       "  (encoder_proj): Linear(in_features=230, out_features=128, bias=True)\n",
       "  (decoder_proj): Linear(in_features=230, out_features=128, bias=True)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (post_cnn): Sequential(\n",
       "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (continuous_proj): Linear(in_features=128, out_features=54, bias=True)\n",
       "  (enum_projs): ModuleDict(\n",
       "    (stage): Linear(in_features=128, out_features=10, bias=True)\n",
       "    (p1_action): Linear(in_features=128, out_features=404, bias=True)\n",
       "    (p1_character): Linear(in_features=128, out_features=35, bias=True)\n",
       "    (p2_action): Linear(in_features=128, out_features=404, bias=True)\n",
       "    (p2_character): Linear(in_features=128, out_features=35, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import MeleeEncoderDecoder\n",
    "model = MeleeEncoderDecoder(\n",
    "        continuous_dim=54,\n",
    "        enum_dims=enum_dims,\n",
    "        embedding_dims=embedding_dims,\n",
    "        d_model=128,\n",
    "        nhead=4,\n",
    "        num_layers=3\n",
    "    )\n",
    "model.load_state_dict(torch.load(\"./models/May2nd_melee_predictor_all.pt\", map_location=torch.device('cpu')))\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8c0af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a running buffer (deque) of all the frames from the past 150 frames, keep track of every 15th frame\n",
    "    # append current frame, then grab the slice of 15 spaced out\n",
    "    # then grab the appropriate slice of 15 spaced out\n",
    "    # then pass that in as a MeleeDataset object\n",
    "\n",
    "# Then with the Melee dataset object, do something similar to training data s.t.\n",
    "    # update Melee dataset object to have optional argument (\"real-time\" or something) telling it to use a passed in list of frames?\n",
    "    # targets will not exist\n",
    "    # only inputs\n",
    "# x_continuous is the batch['continuous_inputs']\n",
    "\n",
    "\n",
    "\n",
    "# Two options (It's kinda messy trying to predict the next 5 frames, so I'ma just grab the first frame from what it predicts):\n",
    "    # 1) Predict every frame \n",
    "        # Less complicated, though a bit questionable since the model is trained at a different temporal frequency maybe (?)\n",
    "    # 2) Predict every 15 frames and keep the same input for the next 15 frames?\n",
    "        # Questionable if this actually works\n",
    "\n",
    "# It would be great to actually just have the model output 1 thing next time AND also have a higher freq. sample rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68f9b69",
   "metadata": {},
   "source": [
    "# Connecting to the Slippi Emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a178c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_slp_file(file_path):\n",
    "    \"\"\"Initialize and connect to a SLP file.\"\"\"\n",
    "    console = melee.Console(\n",
    "        is_dolphin=False,\n",
    "        allow_old_version=True,\n",
    "        path=file_path\n",
    "    )\n",
    "    console.connect()\n",
    "    return console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008a4530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(623, 10, 59)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "example = np.load(\"/Users/alexoon/Desktop/smash_bot/icl_smash/training_data/(...) Falco vs Falco (BABE) [BF] Game_20200122T213211_sequences.npz\", allow_pickle=True)\n",
    "example['inputs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa955b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.,   1.,   3.,   1.,   0.,   0., 613.,   0.,   1.,   1.]),\n",
       " array([0.        , 0.0825    , 0.165     , 0.2475    , 0.33      ,\n",
       "        0.41249999, 0.49499999, 0.57749999, 0.65999999, 0.74249999,\n",
       "        0.82499999]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = example['inputs']\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(x=inputs[:, 0, 4])\n",
    "\n",
    "# consider clamping the values for button presses btw... (i.e. some outputs mean the button shouldn't be pressed by the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e98b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smash_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
